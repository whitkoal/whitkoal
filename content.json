{"meta":{"title":"Bruce","subtitle":null,"description":"待就业青年","author":"Bruce","url":"http://brucy.cn"},"pages":[],"posts":[{"title":"INNODB是如何实现事务的？","slug":"INNODB是如何实现事务的？","date":"2020-02-06T02:19:34.000Z","updated":"2020-02-06T02:21:05.189Z","comments":true,"path":"2020/02/06/INNODB是如何实现事务的？/","link":"","permalink":"http://brucy.cn/2020/02/06/INNODB是如何实现事务的？/","excerpt":"","text":"1、什么是事务通俗来说就是一组SQL语句，而且这组SQL要么同时都执行成功要么同时都不成功。 事务的特性： 特征 说明 原子性（A） 一个事务中的所有操作，要么全都成功，要么全都不成功，不会结束在中间某个环节； 一致性（C） 事务开始之前和结束之后，数据库的完整性没有被破坏； 隔离性（I） 要求每个读写事务的操作对象与其他事务的操作对象能相互隔离； 持久性（D） 事务一旦提交，其结果就会持久化，就算发生宕机也能恢复数据； 2、InnoDB存储引擎对ACID的实现方式利用回滚日志（undo log） 和 重做日志（redo log） 两种表实现事务，并实现 MVCC (多版本并发控制)； 在执行事务的每条SQL时，会先将数据原值写入undo log 中， 然后执行SQL对数据进行修改，最后将修改后的值写入redo log中。 redo log 重做日志包括两部分：1 是内存中的重做日志缓冲 ；2 是重做日志文件。在事务提交时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务commit操作完成才算完成。 当一个事务中的所有SQL都执行成功后，会将redo log 缓存中的数据刷入磁盘，然后提交。 如果发生回滚，会根据undo log 恢复数据。 特征 INNODB实现方式 原子性（A） 回滚日志（undo log）：用于记录数据修改前的状态； 一致性（C） 重做日志（redo log）：用于记录市局修改后的状态； 隔离性（I） 锁：用于资源隔离，分为共享锁和排它锁； 持久性（D） 重做日志（redo log） + 回滚日志（undo log）； 3、MVCC 多版本并发控制查询需要对资源加共享锁（S），数据修改需要对资源加排他锁（X） 排他锁 共享锁 排他锁 不兼容 不兼容 共享锁 不兼容 兼容 MVCC 多版本并发控制：利用undo log使读写不阻塞，实现了可重复读。当一个事务正在对一条数据进行修改时，该资源会被加上排它锁。在事务未提交时对加锁资源进行读操作时，读操作无法读到被锁资源，通过一些特殊的标志符去读undo log 中的数据（过程很复杂），这样读到的都是事务执行之前的数据。 相关资料： mysql技术内幕–innodb存储引擎图解（超级详细）","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://brucy.cn/tags/MySQL/"}],"keywords":[]},{"title":"MySQL常用的存储引擎","slug":"MySQL常用的存储引擎","date":"2020-02-06T02:18:39.000Z","updated":"2020-02-06T02:19:13.151Z","comments":true,"path":"2020/02/06/MySQL常用的存储引擎/","link":"","permalink":"http://brucy.cn/2020/02/06/MySQL常用的存储引擎/","excerpt":"","text":"1、MySQL中常用的存储引擎 引擎名称 是否支持事务 说明 MyISAM N MySQL 5.6 之前的默认引擎，最常用的非事务引擎； CSV N 以CSV格式存储数据，非事务型引擎； Archive N 只允许查询和新增数据而不允许修改数据； Memory N 将数据存储在内存中，不支持事务； InnoDB Y MySQL 5.6 之后的默认引擎，最常用的事务型存储引擎； NDB Y MySQL集群版使用的内存型事务存储引擎； 2、MyISAM 特点： 不支持事务; 以堆表的方式存储，无聚集索引，避免了索引二次查找，提高了查找性能（查找性能优于InnoDB）; 使用表级锁，在查找时会给表加上共享锁，修改表时会给表加上排它锁，读写会相互阻塞； 支持Btree索引、空间索引、全文索引； 适用场景： 不需要事务，读操作远大于写操作的场景； 3、CSV 特点： 不支持事务； 数据以CSV格式存储，可通过直接修改CSV文件来修改数据库数据； 所有列都不能为NULL； 不支持索引； 适用场景：适合作为数据交换的中间表，不适用于频繁查询、更新的场景； 4、Archive 特点： 不支持事务； 表数据使用 Zlib 压缩，节省存储资源； 只支持 Insert 和 Select 操作，不能修改和删除数据； 只允许在自增ID上建立索引； 适用场景：日志和数据采集类应用； 数据归档存储； 5、Memory 特点： 不支持事务； 数据保存在内存中，读写速度快，宕机会失去数据； 所有字段长度固定（char和varchar占用相同大小的空间），且不支持text等类型； 支持Btree索引和Hash索引，默认为Hash索引； 适用场景：用于缓存字典映射表； 缓存周期性分析数据； 与Redis功能相似； 6、InnoDB 特点： 支持事务 ACID； 数据按主键聚集存储，主键的大小会影响索引的性能，若主键顺序经常发生变化，会造成数据迁移或带来某些IO问题； 支持行级锁，读写时只在行上加锁，大大增强了其处理并发业务的性能； 支持MVCC（多版本并发控制），可以避免读写阻塞； 支持Btree索引、自适应Hash索引、全文索引、空间索引； 适用于大多数OLTP场景 7、NDB 特点： 支持事务； 使用时会把数据全都加载到内存中； 支持高可用集群； 支持Ttree索引； 适用场景： 需要数据完全同步的高可用场景；","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://brucy.cn/tags/MySQL/"}],"keywords":[]},{"title":"MySQL用户管理","slug":"MySQL用户管理","date":"2020-02-06T02:17:30.000Z","updated":"2020-02-06T02:18:09.285Z","comments":true,"path":"2020/02/06/MySQL用户管理/","link":"","permalink":"http://brucy.cn/2020/02/06/MySQL用户管理/","excerpt":"","text":"1、如何定义MySQL数据库账号？ MySQL用户名由两部分组成，中间由 @ 符号隔开： 用户名 @ 可访问控制列表 MySQL 5.7 用户名长度只有16个字节；MySQL 8.0 用户名长度为32个字节;可访问控制列表表示“用户可以从哪些服务器上对数据库进行访问”,书写格式如下： %：代表可以从所有外部主机进行访问（默认值） 192.168.1.%：可以从 192.168.1 网段进行访问 localhost：DB 服务器本地访问 多个IP地址用逗号“,”隔开 使用 CREATE USER 命令建立用户 2、用户常用的用户权限 MySQL常用的用户权限列表 语句 说明 Admin Create User 建立新的用户 Grant Option 为其他用户授权 Super 管理服务器 DDL Create 新建数据库、表 Alter 修改表结构 Drop 删除数据库、表 Index 建立和删除索引 DML Select 查询表中的数据 Insert 向表中插入数据 Update 更新表中的数据 Delete 删除表中的数据 Execute 执行存储过程 MySQL中的权限有很多，使用 show privileg 命令查看MySQL支持的权限列表。 3、如何为用户授权？一定要遵循最小授权原则 使用 Grant 命令对用户进行授权 // 将db库中tb表的增删改查权限授予user@ip用户 grant select, insert, update, delete on db.tb to user@ip; 使用 revoke 命令收回用户的授权 revoke delete on db.tb from user@ip;","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://brucy.cn/tags/MySQL/"}],"keywords":[]},{"title":"MySQL各版本对比","slug":"MySQL各版本对比","date":"2020-02-06T02:16:06.000Z","updated":"2020-02-06T02:17:11.855Z","comments":true,"path":"2020/02/06/MySQL各版本对比/","link":"","permalink":"http://brucy.cn/2020/02/06/MySQL各版本对比/","excerpt":"","text":"1、MySQL各版本对比截止到2020年2月5日，MySQL更新到了 MySQL 8.0.19 MySQL各版本对比 MySQL Percona MySQL Maria DB 服务器特性 开源 开源 开源 支持分区表 支持分区表 支持分区表 InnoDB XtraDB XtraDB 企业版监控工具 社区版不提供 Percon Monitor 工具 Monyog 高可用特性 基于日志点复制 基于日志点复制 基于日志点复制 基于Gtid复制 基于Gtid复制 基于Gtid复制 MGR MGR & PXC Galera Cluster MySQL Router Proxy SQL MaxScale 安全特性 企业版防火墙 ProxySQL FireWall MaxScale FireWall 企业版用户审计 审计日志 审计日志 用户密码生命周期 用户密码生命周期 - sha256_password caching_sha2_password sha256_password caching_sha2_password sha256_password ed25519 2、在对MySQL进行升级前要考虑什么？ 升级必须可以给业务带来益处 升级可能给业务带来不好的影响 制定数据库升级方案 制定升级失败回滚方案","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://brucy.cn/tags/MySQL/"}],"keywords":[]},{"title":"Java中的Volatile和Synchronized有何不同？","slug":"Java中的Volatile和Synchronized有何不同？","date":"2020-01-31T14:44:26.000Z","updated":"2020-02-01T02:18:28.489Z","comments":true,"path":"2020/01/31/Java中的Volatile和Synchronized有何不同？/","link":"","permalink":"http://brucy.cn/2020/01/31/Java中的Volatile和Synchronized有何不同？/","excerpt":"","text":"为充分理解Java中多线程同步的实现原理，必须先清除JMM。 一、Java内存模型Java Memory Model 是为了处理并发过程中的可见性、原子性、有序性问题的。 在Java虚拟机中，堆是一个线程共享的内存区域。堆中主要存放对象的实例、静态对象、数组等。堆中存放着一些共享变量。 每条线程都会有一个属于自己的本地内存，本地内存不允许其他线程访问。本地内存中存储的是共享变量的副本。 线程A若要改变主内存中的一个变量，会先改变线程A本地内存中的值，然后再写入主内存。 二、线程通信和线程同步为了让程序在多线程的情况下正确执行，我们必须关注线程通信和线程同步这两个问题 并发中的两个关键问题： 线程之间如何通信？ 共享内存机制，通过共享一些公共状态，从而实现线程间信息交换。—— 隐示通信 消息传递机制，通过直接调用 wait() 、 notify() 、 notifyAll() 这些方法进行线程间通信。—— 显示通信 线程之间如何同步？ 同步是指程序中用于控制不同线程之间操作发生的相对顺序 在共享内存的并发模型中，同步是显示做的。程序员必须在程序中显示的调用某个方法、或某个代码段来达到线程互斥，如： Synchronized 让多个线程排队访问。 在消息传递的并发模型中，由于消息的发送必须在消息接收之前，所以同步是隐示的。 三、Volatile原理对于申明了 Volatile 的变量进行写操作时，JVM会向处理器发送一个带Lock前缀的指令，将变量的缓存值写回主内存，在多处理器的情况下，为保证各个处理器缓存一致，就会实现缓存一致性协议（当其他处理器嗅探到缓存对应的主内存中的值发生了改变，当前缓存的旧值会失效，然后从主内存中加载新值到线程本地内存中缓存起来） volatile使修改后的值立刻可见，从而实现同步。 通过 Volatile 实现同步，可以做到原子性、可见性，但不能做到复合操作的原子性，如： i++ 自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。在多线程的情况下，自增操作的三个子操作可能会分割开执行，导致程序结果出现错误。 四、Synchronized原理通过反编译可以看到Synchronized的原理： Synchronized 原理上是实现了一个锁的机制。当方法或代码块被Synchronized修饰后，执行被修饰方法前先要获得Monitor（监视器，可理解为锁），执行完之后释放Monitor。 执行流程如下： 当Monitor被其他线程占用时，当前线程会进入SynchronizedQueue中等待Monitor被释放。 通过 Synchronized 实现同步，本质是实现了一个可重入锁，可以做到互斥性、可见性。","categories":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://brucy.cn/tags/多线程/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}]},{"title":"Ribbon","slug":"Ribbon","date":"2020-01-17T23:20:24.000Z","updated":"2020-02-11T13:47:08.413Z","comments":true,"path":"2020/01/18/Ribbon/","link":"","permalink":"http://brucy.cn/2020/01/18/Ribbon/","excerpt":"","text":"一、简介Spring Cloud Ribbon是一个基于HTTP和TCP的客户端负载均衡工具，它基于Netflix Ribbon实现。 通过Spring Cloud的封装，可以让我们轻松地将面向服务的REST模版请求自动转换成客户端负载均衡的服务调用。Spring Cloud Ribbon虽然只是一个工具类框架，它不像服务注册中心、配置中心、API网关那样需要独立部署，但是它几乎存在于每一个Spring Cloud构建的微服务和基础设施中。因为微服务间的调用，API网关的请求转发等内容，实际上都是通过Ribbon来实现的，包括后续我们将要介绍的Feign，它也是基于Ribbon实现的工具。所以，对Spring Cloud Ribbon的理解和使用，对于我们使用Spring Cloud来构建微服务非常重要。 二、负载均衡负载均衡是对系统的高可用、网络压力的缓解和处理能力扩容的重要手段之一。 实现负载均衡有两种方式： 一是服务器端负载均衡，其中分为硬件负载均衡和软件负载均衡。硬件负载均衡主要通过在服务器节点之间按照专门用于负载均衡的设备，比如F5等；而软件负载均衡则是通过在服务器上安装一些用于负载均衡功能或模块等软件来完成请求分发工作，比如 Nginx 等。 二是客户端负载均衡，如 Ribbon 。 Ribbon 工作时分为两步：第一先选择Eureka Server， 优先选择同一个Zone且负载较少的Server； 第二步根据用户指定的策略，在从Server取到的服务注册列表中选择一个地址。其中Ribbon提供了多种策略，如轮询round robin（默认）、随机Random、根据响应时间加权等。 Ribbon工作过程如下图： 三、Ribbon的使用如果项目中使用Eureka作为服务注册中心，在使用Ribbon时不需要再导入Ribbon的依赖。在 spring-cloud-starter-eureka 中已经整合了Ribbon。 @LoadBalanceRibbon在使用时也非常简单，服务消费者直接通过调用被 @LoadBalanced 注解修饰过的RestTemplate来实现面向服务的接口调用。Ribbon就会自动完成客户端负载均衡。 Ribbon配置可通过配置文件和@RibbonClient注解的方式对Ribbon进行配置。 配置优先级：配置文件优先级高于 @RibbonClient(configuration = MyRibbonConfig.class) 高于 Ribbon 默认配置。","categories":[{"name":"Ribbon","slug":"Ribbon","permalink":"http://brucy.cn/categories/Ribbon/"}],"tags":[],"keywords":[{"name":"Ribbon","slug":"Ribbon","permalink":"http://brucy.cn/categories/Ribbon/"}]},{"title":"Spring-Security-PasswordEncoder","slug":"Spring-Security-PasswordEncoder","date":"2019-12-24T12:35:12.000Z","updated":"2019-12-24T12:36:13.342Z","comments":true,"path":"2019/12/24/Spring-Security-PasswordEncoder/","link":"","permalink":"http://brucy.cn/2019/12/24/Spring-Security-PasswordEncoder/","excerpt":"","text":"问题描述今天在使用SpringBoot整合spring security，使用内存用户验证，但无响应报错:java.lang.IllegalArgumentException: There is no PasswordEncoder mapped for the id “null” 错误原因这是因为Spring boot 2.0.3引用的security 依赖是 spring security 5.X版本，此版本需要提供一个PasswordEncorder的实例，否则后台汇报错误。 这个错主要发生在Spring-Sercurity5.X版本上，例如SpringBoot2.x。导致这个错误发生主要原因就是在之前版本中的NoOpPasswordEncoder被DelegatingPasswordEncoder取代了，而你保存在数据库中的密码没有没有指定加密方式。 这篇简书有明确的分析 解决方式创建一个类MyPasswordEncoder 实现PasswordEncoder接口 package com.wang.security.config; import org.springframework.security.crypto.password.PasswordEncoder; public class MyPasswordEncoder implements PasswordEncoder { @Override public String encode(CharSequence charSequence) { return charSequence.toString(); } @Override public boolean matches(CharSequence charSequence, String s) { return s.equals(charSequence.toString()); } }在使用认证的时候用MyPasswordEncoder去校验密码 @Configuration @EnableWebSecurity public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { //可以设置内存指定的登录的账号密码,指定角色 //不加.passwordEncoder(new MyPasswordEncoder()) //就不是以明文的方式进行匹配，会报错 auth.inMemoryAuthentication().withUser(&quot;wang&quot;).password(&quot;123456&quot;).roles(&quot;ADMIN&quot;); //.passwordEncoder(new MyPasswordEncoder())。 //这样，页面提交时候，密码以明文的方式进行匹配。 auth.inMemoryAuthentication().passwordEncoder(new MyPasswordEncoder()).withUser(&quot;wang&quot;).password(&quot;123456&quot;).roles(&quot;ADMIN&quot;); } @Override protected void configure(HttpSecurity http) throws Exception { //设置登录,注销，表单登录不用拦截，其他请求要拦截 http.authorizeRequests().antMatchers(&quot;/&quot;).permitAll() .anyRequest().authenticated() .and() .logout().permitAll() .and() .formLogin(); //关闭默认的csrf认证 http.csrf().disable(); } 转载于： java.lang.IllegalArgumentException: There is no PasswordEncoder mapped for the id “null”","categories":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}]},{"title":"MongoDB搭建副本集","slug":"MongoDB搭建副本集","date":"2019-12-23T02:50:56.000Z","updated":"2020-02-11T13:59:34.542Z","comments":true,"path":"2019/12/23/MongoDB搭建副本集/","link":"","permalink":"http://brucy.cn/2019/12/23/MongoDB搭建副本集/","excerpt":"","text":"一、环境搭建1、副本集结构本文将配置一个由 3 个节点组成的副本集，其中： 一个主节点 一个从节点，可以在选举中成为主库一个aribiter节点，在选举中，只进行投票，不能成为主库 副本集形式如下图： 2、运行环境分别为3台服务器安装MongoDB 服务器均为： CentOS 6.10 64bitmongoDB版本为： MongoDB v4.0.13 二、权限配置1、生成key用于验证openssl rand -base64 745 &gt; “key的生成路径” openssl rand -base64 745 &gt; /data/mongo_set/usercenter/30010/mongodb-keyfile chmod 600 /data/mongo_set/usercenter/30010/mon-keyfile该key的权限必须是400，否则会导致认证失败 将生成的key分别拷贝到其他两台服务器上。 2、 配置文件security.keyFile：写刚才生成的key的路径。 systemLog: destination: file path: /opt/soft/mongodb/data/rs1.log logAppend: true processManagement: fork: true net: port: 27018 bindIp: 0.0.0.0 storage: dbPath: /opt/soft/mongodb/data/rs1 replication: oplogSizeMB: 100 replSetName: rs1 security: keyFile: /opt/soft/mongodb/key authorization: enabled Arbiter节点的配置文件也与此相同。 正式开始配置副本集1、分别启动3台服务器上的MongoDB服务命令如下： mongod -config 配置文件路径 mongod -config /usr/local/mongodb-4.0.2/mongodb.conf # 或者 mongod -f /usr/local/mongodb-4.0.2/mongodb.conf3个MongoDB服务都启动后任意连接一个MongoDB服务 –port 后加端口号，可在配置文件中进行配置，默认端口号为27017 mongo --port 270182、 复制集管理操作2.1、查看复制集状态： rs.status(); # 查看整体复制集状态rs.isMaster(); # 查看当前是否是主节点 2.2、添加删除节点 rs.add(“ip:port”); # 新增从节点rs.addArb(“ip:port”); # 新增仲裁节点rs.remove(“ip:port”); # 删除一个节点 2.3、查看副本集的配置信息 my_repl:PRIMARY&gt; rs.config() 2.4、查看副本集各成员的状态 my_repl:PRIMARY&gt; rs.status() 3、初始化副本集切换到admin数据库中，用 rs.initiate() 命令进行初始化。 初始化后稍等一会儿，当前节点会自动变成PRIMARY节点。 &gt; use admin switched to db admin &gt; rs.initiate() { &quot;info2&quot; : &quot;no configuration specified. Using a default configuration for the set&quot;, &quot;me&quot; : &quot;huawei:27018&quot;, &quot;ok&quot; : 1 } rs1:OTHER&gt; 4、创建用户并完成认证创建用户需在 admin 数据库中完成，可用 use admin 命令切换到 admin 数据库。 本示例为了方便直接创建了有最高权限（root）的用户。 rs1:PRIMARY&gt; db.createUser({ ... user: &quot;root&quot;, ... pwd: &quot;root&quot;, ... roles: [{role: &quot;root&quot;, db:&quot;admin&quot;}] ... }) Successfully added user: { &quot;user&quot; : &quot;root&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;root&quot;, &quot;db&quot; : &quot;admin&quot; } ] }用 db.auth(&quot;用户名&quot; , &quot;密码&quot;) 命令来完成认证，返回值为 1 则认证成功。 如果遇到认证失败的情况，请检查配置文件中 keyFile 路径是否写对，或 key 的权限是否为400（仅root用户可读）。 rs1:PRIMARY&gt; db.auth(&quot;root&quot;, &quot;root&quot;) 15、添加副本 rs1:PRIMARY&gt; rs.add(&quot;172.81.24x.xx1:27018&quot;) { &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1577068463, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1577068463, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;UzvrLpDSEAkoC6oOr9Yrh5047uI=&quot;), &quot;keyId&quot; : NumberLong(&quot;6773456703338840066&quot;) } } } rs1:PRIMARY&gt; rs.status() { &quot;set&quot; : &quot;rs1&quot;, &quot;date&quot; : ISODate(&quot;2019-12-23T02:34:33.651Z&quot;), &quot;myState&quot; : 1, &quot;term&quot; : NumberLong(1), &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;heartbeatIntervalMillis&quot; : NumberLong(2000), &quot;optimes&quot; : { &quot;lastCommittedOpTime&quot; : { &quot;ts&quot; : Timestamp(1577068454, 1), &quot;t&quot; : NumberLong(1) }, &quot;appliedOpTime&quot; : { &quot;ts&quot; : Timestamp(1577068463, 1), &quot;t&quot; : NumberLong(1) }, &quot;durableOpTime&quot; : { &quot;ts&quot; : Timestamp(1577068463, 1), &quot;t&quot; : NumberLong(1) } }, &quot;lastStableCheckpointTimestamp&quot; : Timestamp(1577068454, 1), &quot;electionCandidateMetrics&quot; : { &quot;lastElectionReason&quot; : &quot;electionTimeout&quot;, &quot;lastElectionDate&quot; : ISODate(&quot;2019-12-23T02:31:23.678Z&quot;), &quot;electionTerm&quot; : NumberLong(1), &quot;lastCommittedOpTimeAtElection&quot; : { &quot;ts&quot; : Timestamp(0, 0), &quot;t&quot; : NumberLong(-1) }, &quot;lastSeenOpTimeAtElection&quot; : { &quot;ts&quot; : Timestamp(1577068283, 1), &quot;t&quot; : NumberLong(-1) }, &quot;numVotesNeeded&quot; : 1, &quot;priorityAtElection&quot; : 1, &quot;electionTimeoutMillis&quot; : NumberLong(10000), &quot;newTermStartDate&quot; : ISODate(&quot;2019-12-23T02:31:24.689Z&quot;), &quot;wMajorityWriteAvailabilityDate&quot; : ISODate(&quot;2019-12-23T02:31:24.706Z&quot;) }, &quot;members&quot; : [ { &quot;_id&quot; : 0, &quot;name&quot; : &quot;huawei:27018&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 655, &quot;optime&quot; : { &quot;ts&quot; : Timestamp(1577068463, 1), &quot;t&quot; : NumberLong(1) }, &quot;optimeDate&quot; : ISODate(&quot;2019-12-23T02:34:23Z&quot;), &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;&quot;, &quot;electionTime&quot; : Timestamp(1577068283, 2), &quot;electionDate&quot; : ISODate(&quot;2019-12-23T02:31:23Z&quot;), &quot;configVersion&quot; : 2, &quot;self&quot; : true, &quot;lastHeartbeatMessage&quot; : &quot;&quot; }, { &quot;_id&quot; : 1, &quot;name&quot; : &quot;172.81.242.231:27018&quot;, &quot;health&quot; : 1, &quot;state&quot; : 0, &quot;stateStr&quot; : &quot;STARTUP&quot;, &quot;uptime&quot; : 9, &quot;optime&quot; : { &quot;ts&quot; : Timestamp(0, 0), &quot;t&quot; : NumberLong(-1) }, &quot;optimeDurable&quot; : { &quot;ts&quot; : Timestamp(0, 0), &quot;t&quot; : NumberLong(-1) }, &quot;optimeDate&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2019-12-23T02:34:32.029Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;pingMs&quot; : NumberLong(32), &quot;lastHeartbeatMessage&quot; : &quot;&quot;, &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : -2 } ], &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1577068463, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1577068463, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;UzvrLpDSEAkoC6oOr9Yrh5047uI=&quot;), &quot;keyId&quot; : NumberLong(&quot;6773456703338840066&quot;) } } } 添加Arbiter节点 rs1:PRIMARY&gt; rs.addArb(&quot;172.81.242.231:27019&quot;) { &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1577068539, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1577068539, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;1p1aVui3drDMudUDcaO6JNP+LZA=&quot;), &quot;keyId&quot; : NumberLong(&quot;6773456703338840066&quot;) } } } 使用 rs.status() 命令查看当前副本集状态。 rs1:PRIMARY&gt; rs.status() { &quot;set&quot; : &quot;rs1&quot;, &quot;date&quot; : ISODate(&quot;2019-12-23T02:35:59.842Z&quot;), &quot;myState&quot; : 1, &quot;term&quot; : NumberLong(1), &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;heartbeatIntervalMillis&quot; : NumberLong(2000), &quot;optimes&quot; : { &quot;lastCommittedOpTime&quot; : { &quot;ts&quot; : Timestamp(1577068454, 1), &quot;t&quot; : NumberLong(1) }, &quot;appliedOpTime&quot; : { &quot;ts&quot; : Timestamp(1577068554, 1), &quot;t&quot; : NumberLong(1) }, &quot;durableOpTime&quot; : { &quot;ts&quot; : Timestamp(1577068554, 1), &quot;t&quot; : NumberLong(1) } }, &quot;lastStableCheckpointTimestamp&quot; : Timestamp(1577068454, 1), &quot;electionCandidateMetrics&quot; : { &quot;lastElectionReason&quot; : &quot;electionTimeout&quot;, &quot;lastElectionDate&quot; : ISODate(&quot;2019-12-23T02:31:23.678Z&quot;), &quot;electionTerm&quot; : NumberLong(1), &quot;lastCommittedOpTimeAtElection&quot; : { &quot;ts&quot; : Timestamp(0, 0), &quot;t&quot; : NumberLong(-1) }, &quot;lastSeenOpTimeAtElection&quot; : { &quot;ts&quot; : Timestamp(1577068283, 1), &quot;t&quot; : NumberLong(-1) }, &quot;numVotesNeeded&quot; : 1, &quot;priorityAtElection&quot; : 1, &quot;electionTimeoutMillis&quot; : NumberLong(10000), &quot;newTermStartDate&quot; : ISODate(&quot;2019-12-23T02:31:24.689Z&quot;), &quot;wMajorityWriteAvailabilityDate&quot; : ISODate(&quot;2019-12-23T02:31:24.706Z&quot;) }, &quot;members&quot; : [ { &quot;_id&quot; : 0, &quot;name&quot; : &quot;huawei:27018&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 741, &quot;optime&quot; : { &quot;ts&quot; : Timestamp(1577068554, 1), &quot;t&quot; : NumberLong(1) }, &quot;optimeDate&quot; : ISODate(&quot;2019-12-23T02:35:54Z&quot;), &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;&quot;, &quot;electionTime&quot; : Timestamp(1577068283, 2), &quot;electionDate&quot; : ISODate(&quot;2019-12-23T02:31:23Z&quot;), &quot;configVersion&quot; : 3, &quot;self&quot; : true, &quot;lastHeartbeatMessage&quot; : &quot;&quot; }, { &quot;_id&quot; : 1, &quot;name&quot; : &quot;172.81.242.231:27018&quot;, &quot;health&quot; : 1, &quot;state&quot; : 0, &quot;stateStr&quot; : &quot;STARTUP&quot;, &quot;uptime&quot; : 95, &quot;optime&quot; : { &quot;ts&quot; : Timestamp(0, 0), &quot;t&quot; : NumberLong(-1) }, &quot;optimeDurable&quot; : { &quot;ts&quot; : Timestamp(0, 0), &quot;t&quot; : NumberLong(-1) }, &quot;optimeDate&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;optimeDurableDate&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;lastHeartbeat&quot; : ISODate(&quot;2019-12-23T02:35:59.754Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;pingMs&quot; : NumberLong(32), &quot;lastHeartbeatMessage&quot; : &quot;&quot;, &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : -2 }, { &quot;_id&quot; : 2, &quot;name&quot; : &quot;172.81.242.231:27019&quot;, &quot;health&quot; : 1, &quot;state&quot; : 0, &quot;stateStr&quot; : &quot;STARTUP&quot;, &quot;uptime&quot; : 20, &quot;lastHeartbeat&quot; : ISODate(&quot;2019-12-23T02:35:57.881Z&quot;), &quot;lastHeartbeatRecv&quot; : ISODate(&quot;1970-01-01T00:00:00Z&quot;), &quot;pingMs&quot; : NumberLong(31), &quot;lastHeartbeatMessage&quot; : &quot;&quot;, &quot;syncingTo&quot; : &quot;&quot;, &quot;syncSourceHost&quot; : &quot;&quot;, &quot;syncSourceId&quot; : -1, &quot;infoMessage&quot; : &quot;&quot;, &quot;configVersion&quot; : -2 } ], &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1577068554, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1577068554, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;m5nsHVXYsiAD/B5MbFfE7KGZ+V0=&quot;), &quot;keyId&quot; : NumberLong(&quot;6773456703338840066&quot;) } } }","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://brucy.cn/categories/MongoDB/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://brucy.cn/tags/MongoDB/"}],"keywords":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://brucy.cn/categories/MongoDB/"}]},{"title":"MongoDB配置文件部分选项解释","slug":"MongoDB配置文件部分选项解释","date":"2019-12-14T08:51:10.000Z","updated":"2019-12-14T08:52:01.031Z","comments":true,"path":"2019/12/14/MongoDB配置文件部分选项解释/","link":"","permalink":"http://brucy.cn/2019/12/14/MongoDB配置文件部分选项解释/","excerpt":"","text":"systemLog: verbosity: &lt;int&gt; 组件的默认日志消息详细级别。详细级别决定了MongoDB输出的信息和调试消息的数量。 0是MongoDB的默认日志冗余级别，用来包含信息消息。 从1到5增加详细级别以包含调试消息。 quiet: &lt;boolean&gt; 在一个试图限制输出数量的安静模式下运行mongos或mongod。 traceAllExceptions: &lt;boolean&gt; 打印详细信息以便调试。用于与支持相关的故障排除的附加日志记录。 syslogFacility: &lt;string&gt; 将消息记录到syslog时使用的功能级别。 path: &lt;string&gt; MongoDB在指定的路径上创建日志文件。 logAppend: &lt;boolean&gt; 当为 true 时，当mongos或mongod实例重新启动时， mongos或mongod将新条目附加到现有日志文件的末尾。 如果没有这个选项，mongod将备份现有的日志并创建一个新文件。 logRotate: &lt;string&gt; destination: &lt;string&gt; timeStampFormat: &lt;string&gt; 日志消息中时间戳的时间格式 component: accessControl: verbosity: &lt;int&gt; 日志消息详细级别 command: verbosity: &lt;int&gt; 日志消息详细级别 processManagement: fork: &lt;boolean&gt; 启用在后台运行mongos或mongod进程的守护进程模式。 pidFilePath: &lt;string&gt; 指定一个文件位置来存储mongos或mongod进程的进程ID (PID)。 timeZoneInfo: &lt;string&gt; 加载时区数据库的完整路径。 cloud: monitoring: free: state: &lt;string&gt; 启用或禁用免费的MongoDB云监控。 tags: &lt;string&gt; 用来描述云监控环境的标签 net: port: &lt;int&gt; MongoDB实例监听客户端连接的TCP端口。 bindIp: &lt;string&gt; 主机名或IP地址，mongos或mongod应在其上侦听客户端连接。 您可以将mongos或mongod连接到任何接口。若要绑定到多个地址，请输入逗号分隔的值列表。 bindIpAll: &lt;boolean&gt; 绑定到所有地址 maxIncomingConnections: &lt;int&gt; 最大并发连接数。 wireObjectCheck: &lt;boolean&gt; 如果为true，检查客户端的所有请求 ipv6: &lt;boolean&gt; 如果为true，支持IPv6。默认情况下禁用IPv6支持。 unixDomainSocket: enabled: &lt;boolean&gt; 在UNIX域套接字上启用或禁用监听。 pathPrefix: &lt;string&gt; filePermissions: &lt;int&gt; compression: compressors: &lt;string&gt; 指定用于此mongod或mongos实例之间通信的默认压缩器 serviceExecutor: &lt;string&gt; 确定mongos或mongod用于执行客户端请求的线程和执行模型。 security: keyFile: &lt;string&gt; 密钥文件的路径存储了MongoDB实例用于在分片集群或副本集中相互验证的共享秘钥。 clusterAuthMode: &lt;string&gt; 用于集群身份验证的身份验证模式。 authorization: &lt;string&gt; 启用或禁用基于角色的访问控制(RBAC)来控制每个用户对数据库资源和操作的访问。 transitionToAuth: &lt;boolean&gt; 启用或禁用服务器端JavaScript执行。 storage: dbPath: &lt;string&gt; mongod实例存储其数据的目录。 indexBuildRetry: &lt;boolean&gt; 指定mongod是否在下一次启动时重新构建不完整的索引。 这适用于mongod在关闭或在索引构建过程中停止后重新启动的情况。 在这种情况下，mongod总是删除任何不完整的索引，然后在默认情况下尝试重新构建它们。 若要阻止mongod重新构建索引，请将此选项设置为false。 journal: enabled: &lt;boolean&gt; 启用或禁用持久性日志，以确保数据文件保持有效和可恢复。 commitIntervalMs: &lt;num&gt; directoryPerDB: &lt;boolean&gt; syncPeriodSecs: &lt;int&gt; engine: &lt;string&gt; mongod数据库的存储引擎[wiredTiger(默认)、inMemory] wiredTiger: engineConfig: cacheSizeGB: &lt;number&gt; 内部缓存的最大大小。索引构建所消耗的内存与WiredTiger缓存内存是分开的 journalCompressor: &lt;string&gt; 指定用于压缩WiredTiger日志数据的压缩类型。 directoryForIndexes: &lt;boolean&gt; 如果为true，mongod将索引和集合存储在data(即storage.dbPath)目录下的不同子目录中。 indexConfig: prefixCompression: &lt;boolean&gt; 启用或禁用索引数据的前缀压缩 inMemory: engineConfig: inMemorySizeGB: &lt;number&gt; 默认情况下，内存存储引擎使用50%的物理RAM减去1 GB。 replication: oplogSizeMB: &lt;int&gt; 复制操作日志的最大大小(以兆为单位)。 replSetName: &lt;string&gt; mongod所属的复制集的名称。复制集中的所有主机必须具有相同的集名。 sharding: clusterRole: &lt;string&gt; mongod实例在切分集群中的角色[configsvr、shardsvr] archiveMovedChunks: &lt;boolean&gt; chunk是否保存正在从shard迁移走的数据，默认为不保存（false）sharding: configDB: &lt;string&gt; 指定config server副本集的至少一个成员的主机名和端口。示例： sharding: configDB: &lt;configReplSetName&gt;/cfg1.example.net:27019, cfg2.example.net:27019,... 更多详细介绍请看官方文档","categories":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://brucy.cn/tags/MongoDB/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}]},{"title":"连接远程MongoDB数据库","slug":"连接远程MongoDB数据库","date":"2019-12-12T02:53:28.000Z","updated":"2019-12-12T03:32:25.445Z","comments":true,"path":"2019/12/12/连接远程MongoDB数据库/","link":"","permalink":"http://brucy.cn/2019/12/12/连接远程MongoDB数据库/","excerpt":"","text":"spring-mongodb连接远程MongoDB数据库需要注意以下几点：一、服务器放通MongoDB端口在云服务器控制台就可以很方便的打开 以华为云为例： 二、添加MongoDB用户切换到admin库 use adminuser 和 pwd 按自己的用户名和密码修改 db.createUser( { user: &quot;test&quot;, pwd: &quot;123456&quot;, roles: [&quot;userAdminAnyDatabase&quot;, &quot;dbAdminAnyDatabase&quot;, &quot;readWriteAnyDatabase&quot;, &quot;clusterAdmin&quot;] } )添加成功后返回： Successfully added user: { &quot;user&quot; : &quot;csdn&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot;, &quot;dbAdminAnyDatabase&quot;, &quot;readWriteAnyDatabase&quot;, &quot;clusterAdmin&quot; ] }更多添加验证用户的操作看这里 三、配置MongoDB认证方式 com.mongodb.MongoCommandException: Command failed with error 18 (AuthenticationFailed): ‘Authentication failed.’ on server 121.36.39.114:27017. The full response is {“ok”: 0.0, “errmsg”: “Authentication failed.”, “code”: 18, “codeName”: “AuthenticationFailed”} 如果报这种认证失败错误，很可能是MongoDB与spring-mongodb的认证方式不同。 mongodb的认证机制有2种： SCRAM-SHA-1和MONGODB-CR 。3.0之后版本默认为： SCRAM-SHA-1 ； spring-mongodb默认为： MONGODB-CR ； 查看当前MongoDB的认证方式： use admin db.system.version.findOne({&quot;_id&quot;:&quot;authSchema&quot;})查询结果如下： { &quot;_id&quot; : &quot;authSchema&quot;, &quot;currentVersion&quot; : 5 } 值为3表示：MONGODB-CR 值为5表示：SCRAM-SHA-1 有两种解决方法，一是该数据库的认证方式、二是改spring-mongodb的认证方式。 修改spring-mongodb的认证方式更简单，只需在 application.yml 中将数据源做如下配置： spring: data: mongodb: uri: mongodb://用户名:密码@121.36.39.134（地址）:27017（端口）/mytest（数据库名）?authSource=admin&amp;authMechanism=SCRAM-SHA-1 完成以上步骤基本就可以连接到远程MongoDB数据库了","categories":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}]},{"title":"基础数据结构-02、链表","slug":"基础数据结构-02、链表","date":"2019-12-10T03:28:14.000Z","updated":"2019-12-10T12:05:25.690Z","comments":true,"path":"2019/12/10/基础数据结构-02、链表/","link":"","permalink":"http://brucy.cn/2019/12/10/基础数据结构-02、链表/","excerpt":"","text":"一、链表底层的存储结构从下图中我们看到，数组需要一块连续的内存空间来存储，对内存的要求比较高。如果我们申请一个100MB大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于100MB，仍然会申请失败。 而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针 ”将一组零散的内存块串联起来使用，所以如果我们申请的是100MB大小的链表，根本不会有问题。 单链表、双向链表和循环链表链表有很多种，最常见的就是单链表、双向链表和循环链表这三种。 单链表：每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。 循环链表循环链表的尾结点指针是指向链表的头结点。它像一个环一样首尾相连，所以叫作“循环”链表。 双向链表：顾名思义，它支持两个方向，每个结点不止有一个后继指针next指向后面的结点，还有一个前驱指针prev指向前面的结点。 链表经典题LeetCode ： 206，141，21，19，876题 206. 反转链表反转一个单链表。 示例: 输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL 题解： class Solution { public ListNode reverseList(ListNode head) { if(head == null || head.next == null) return head; ListNode a = head; ListNode b = head.next; ListNode c = head.next.next; head.next = null; while(c != null){ b.next = a; a = b; b = c; c = c.next; } b.next = a; return b; } }141.环形链表给定一个链表，判断链表中是否有环。 示例 1： 输入：head = [3,2,0,-4], pos = 1输出：true解释：链表中有一个环，其尾部连接到第二个节点。 题解： /** * class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public boolean hasCycle(ListNode head) { if(head == null || head.next == null) return false; ListNode low = head; ListNode fast = head.next; while(low != fast){ if(fast == null || fast.next == null) return false; low = low.next; fast = fast.next; fast = fast.next; } return true; } }21. 合并两个有序链表将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例： 输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 题解： class Solution { public ListNode mergeTwoLists(ListNode l1, ListNode l2) { if(l1 == null) return l2; if(l2 == null) return l1; if(l1.val &gt; l2.val){ l2.next = mergeTwoLists(l1, l2.next); return l2; }else{ l1.next = mergeTwoLists(l1.next, l2); return l1; } } }详细解题思路 19. 删除链表的倒数第N个节点给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。 示例： 给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n = 2. 当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5. 题解： 我们可以使用两个指针。第一个指针从列表的开头向前移动 n+1 步，而第二个指针将从列表的开头出发。现在，这两个指针被 n 个结点分开。我们通过同时移动两个指针向前来保持这个恒定的间隔，直到第一个指针到达最后一个结点。此时第二个指针将指向从最后一个结点数起的第 n 个结点。这样遍历一次后第一个指针走到了尾结点，第二个指针的下一个结点就是需删除的结点。我们重新链接第二个指针所引用的结点的 next 指针指向该结点的下下个结点。 public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy = new ListNode(0); dummy.next = head; ListNode first = dummy; ListNode second = dummy; // Advances first pointer so that the gap between first and second is n nodes apart for (int i = 1; i &lt;= n + 1; i++) { first = first.next; } // Move first to the end, maintaining the gap while (first != null) { first = first.next; second = second.next; } second.next = second.next.next; return dummy.next; }876. 链表的中间结点给定一个带有头结点 head 的非空单链表，返回链表的中间结点。 如果有两个中间结点，则返回第二个中间结点。 示例 1： 输入：[1,2,3,4,5]输出：此列表中的结点 3 (序列化形式：[3,4,5])返回的结点值为 3 。 (测评系统对该结点序列化表述是 [3,4,5])。注意，我们返回了一个 ListNode 类型的对象 ans，这样：ans.val = 3, ans.next.val = 4, ans.next.next.val = 5, 以及 ans.next.next.next = NULL. 示例 2： 输入：[1,2,3,4,5,6]输出：此列表中的结点 4 (序列化形式：[4,5,6])由于该列表有两个中间结点，值分别为 3 和 4，我们返回第二个结点。 思路： 快慢指针法，快指针每次走2步，慢指针每次走1步。当快指针走到尾结点时，慢指针刚好走到中间结点。 题解： class Solution { public ListNode middleNode(ListNode head) { ListNode fast = head; ListNode low = head; while(fast != null &amp;&amp; fast.next != null){ fast = fast.next.next; low = low.next; } return low; } }","categories":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://brucy.cn/tags/数据结构与算法/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}]},{"title":"基础数据结构-01、数组","slug":"基础数据结构-01、数组","date":"2019-12-09T10:29:47.000Z","updated":"2019-12-09T11:58:54.536Z","comments":true,"path":"2019/12/09/基础数据结构-01、数组/","link":"","permalink":"http://brucy.cn/2019/12/09/基础数据结构-01、数组/","excerpt":"","text":"什么是数组？数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。 这个定义里有几个关键词，理解了这几个关键词，我想你就能彻底掌握数组的概念了。 第一是线性表 （Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。 第二个是 连续的内存空间和相同类型的数据 。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。 但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。 数组是如何实现随机访问的？我们拿一个长度为10的int类型的数组int[] a = new int[10]来举例。在我画的这个图中，计算机给数组a[10]，分配了一块连续内存空间1000～1039，其中，内存块的首地址为base_address = 1000。 我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址： a[i]_address = base_address + i * data_type_size 其中data_type_size表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是int类型数据，所以data_type_size就为4个字节。 插入操作假设数组的长度为n，现在，如果我们需要将一个数据插入到数组中的第k个位置。为了把第k个位置腾出来，给新来的数据，我们需要将第k～n这部分的元素都顺序地往后挪一位。那插入操作的时间复杂度是多少呢？你可以自己先试着分析一下。 如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为(1+2+…n)/n=O(n)。 删除操作跟插入数据类似，如果我们要删除第k个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。 和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为O(1)；如果删除开头的数据，则最坏情况时间复杂度为O(n)；平均情况时间复杂度也为O(n)。 容器能否完全替代数组？针对数组类型，很多语言都提供了容器类，比如Java中的ArrayList、C++ STL中的vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？ 这里我拿Java语言来举例。如果你是Java工程师，几乎天天都在用ArrayList，对它应该非常熟悉。那它与数组相比，到底有哪些优势呢？ 我个人觉得，ArrayList最大的优势就是 可以将很多数组操作的细节封装起来 。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是支持动态扩容。 例如使用ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为1.5倍大小。 为什么数组要从0开始编号，而不是从1开始呢？在大部分编程语言中，数组都是从0开始编号的，为什么数组要从0开始编号，而不是从1开始呢？ 从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用a来表示数组的首地址，a[0]就是偏移为0的位置，也就是首地址，a[k]就表示偏移k个type_size的位置，所以计算a[k]的内存地址只需要用这个公式： a[k]_address = base_address + k * type_size 但是，如果数组从1开始计数，那我们计算数组元素a[k]的内存地址就会变为： a[k]_address = base_address + (k-1)*type_size 对比两个公式，我们不难发现，从1开始编号，每次随机访问数组元素都多了一次减法运算，对于CPU来说，就是多了一次减法指令。所以为了减少一次减法操作，数组选择了从0开始编号，而不是从1开始。 不过我认为，上面解释得再多其实都算不上压倒性的证明，说数组起始编号非0开始不可。所以我觉得最主要的原因可能是历史原因。 C语言设计者用0开始计数数组下标，之后的Java、JavaScript等高级语言都效仿了C语言，或者说，为了在一定程度上减少C语言程序员学习Java的学习成本，因此继续沿用了从0开始计数的习惯。实际上，很多语言中数组也并不是从0开始计数的，比如Matlab。甚至还有一些语言支持负数下标，比如Python。","categories":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://brucy.cn/tags/数据结构与算法/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://brucy.cn/categories/技术/"}]},{"title":"RabbitMQ基本概念介绍","slug":"RabbitMQ基本概念介绍","date":"2019-12-07T12:28:18.000Z","updated":"2019-12-07T13:06:51.762Z","comments":true,"path":"2019/12/07/RabbitMQ基本概念介绍/","link":"","permalink":"http://brucy.cn/2019/12/07/RabbitMQ基本概念介绍/","excerpt":"","text":"RabbitMQ中涉及到的几个概念介绍RabbitMQ 是信息传输的中间者。本质上，他从生产者（producers）接收消息，转发这些消息给消费者（consumers）.换句话说，它能够按根据你指定的规则进行消息转发、缓冲、和持久化。 RabbitMQ 的一些常见的术语：producer ：消息生产者。一个发送消息的程序是一个producer(生产者)。 consumer ：消息消费者。consumer是等待接收消息的程序。 broker ：消息转发者，也就是我们RabbitMQ服务端充当的功能。 virtual host ：虚拟主机，每个RabbitMQ都能创建很多 vhost ，称之为虚拟主机。每个虚拟主机都是一个mini版的RabbitMQ，拥有自己的队列，交换器和绑定，可以设置独立的权限机制。 vhost的一些特性： RabbitMQ默认的 vhost 是“/”，Rabbit自己创建好的，开箱即用。 多个 vhost 是相互隔离的，多个 vhost 无法通讯，实现了多层分离。 创建用户的时候必须指定 vhost 。 Queue（队列） ：类似邮箱。依存于RabbitMQ内部。虽然消息通过RabbitMQ在你的应用中传递，但是它们只能存储在queue中。队列不受任何限制，可以存储任何数量的消息—本质上是一个无限制的缓存。很多producers可以通过同一个队列发送消息，相同的很多consumers可以从同一个队列上接收消息。Queue 接收 exchange 路由过来的消息，我们可以对队列内容进行持久化操作，那么queue到底接收那个exchange路由的消息呢？这个时候就要用到binding key(绑定键)了，绑定键会将队列和exchange进行绑定，至于绑定方式，RabbitMQ提供了多种方式。 exchange ：交换机，他是和producer直接进行打交道的，有点类似于路由器的功能，主要就是进行转发操作的呗，那么producer到底用哪个exchange进行路由呢？这个取决于routing key(路由键)，每个消息都有这个键，我们也可以自己设定，其实就是一字符串； 注意：producer（生产者）,consumer（消费者）,broker（RabbitMQ服务）并不需要部署在同一台机器上，实际上在大多数实际的应用中，也不会部署在同一台机器上。 RabbitMQ使用示例：producer消息发送步骤： 创建ConnectionFactory，并设置参数，如：hostname、portNumber等 利用ConnectionFactory创建一个连接（Connection） 利用Connection创建一个Channel通道（信道） 创建Queue并和Channe进行绑定 创建消息并发送 注意 ：在我们当前的例子中，并没有用到exchange交换机，RabbitMQ默认情况下是会创建一个空字符串名字的exchange的，如果我们没有创建自己的exchange的话，默认就是使用的这个exchange； producer端代码示例：public class Sender { private final static String QUEUE_NAME = &quot;MyQueue&quot;; public static void main(String[] args) { send(); } public static void send() { ConnectionFactory factory = null; Connection connection = null; Channel channel = null; try { factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); connection = factory.newConnection(); channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message = &quot;my first message .....&quot;; channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(&quot;已经发送消息.....&quot;+message); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); }finally{ try { //关闭资源 channel.close(); connection.close(); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } } }consumer接收消息步骤： 创建ConnectionFactory， 并设置参数，如：hostname、portNumber等 利用ConnectionFactory创建一个Connection连接 利用Connection创建一个Channel通道 将queue和Channel进行绑定，注意这里的queue名字要和前面producer创建的queue一致 创建消费者Consumer来接收消息，同时将消费者和queue进行绑定 consumer端代码：public class Receiver { private final static String QUEUE_NAME = &quot;MyQueue&quot;; public static void main(String[] args) { receive(); } public static void receive() { ConnectionFactory factory = null; Connection connection = null; Channel channel = null; try { factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); connection = factory.newConnection(); channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); Consumer consumer = new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException { String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot;收到消息.....&quot;+message); }}; channel.basicConsume(QUEUE_NAME, true,consumer); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); }finally{ try { //关闭资源 channel.close(); connection.close(); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } } } }此示例工作示意图如下： 参考资料： RabbitMQ 入门 Helloworld RabbitMQ系列(一)：Windows下RabbitMQ安装及入门","categories":[],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://brucy.cn/tags/RabbitMQ/"}],"keywords":[]},{"title":"MongoDB常用语句(一)","slug":"MongoDB常用语句(一)","date":"2019-12-03T12:44:06.000Z","updated":"2019-12-05T03:42:49.551Z","comments":true,"path":"2019/12/03/MongoDB常用语句(一)/","link":"","permalink":"http://brucy.cn/2019/12/03/MongoDB常用语句(一)/","excerpt":"","text":"use 命令 创建/选择 数据库MongoDB使用 use DATABASE_NAME 命令来创建数据库。如果指定的数据库DATABASE_NAME不存在，则该命令将创建一个新的数据库，否则返回现有的数据库。 MongoDB Enterprise &gt; use mydatabase switched to db mydatabase查看数据库列表：show dbs 刚刚创建的mydatabase不在其中，MongoDB不会显示空数据库 MongoDB Enterprise &gt; show dbs admin 0.000GB config 0.000GB local 0.000GB在 MongoDB 中默认数据库是：test 如果您还没有创建过任何数据库，则集合/文档将存储在test数据库中。 删数据库MongoDB中的 db.dropDatabase() 命令用于删除现有的数据库。 MongoDB Enterprise &gt; use aa switched to db aa MongoDB Enterprise &gt; db.dropDatabase() { &quot;ok&quot; : 1 }创建集合 createCollection()方法MongoDB 的 db.createCollection(name，options) 方法用于在MongoDB 中创建集合。 在命令中，name 是要创建的集合的名称。 options是一个文档，用于指定集合的配置 参数 类型 描述 name String 要创建的集合的名称 options Document (可选)指定有关内存大小和索引的选项 options 参数是可选的，因此只需要指定集合的名称。 以下是可以使用的选项列表： 字段 类型 描述 capped Boolean (可选)如果为true，则启用封闭的集合。上限集合是固定大小的集合，它在达到其最大大小时自动覆盖其最旧的条目。 如果指定true，则还需要指定size参数。 autoIndexId Boolean (可选)如果为true，则在_id字段上自动创建索引。默认值为false。 size 数字 (可选)指定上限集合的最大大小(以字节为单位)。 如果capped为true，那么还需要指定此字段的值。 max 数字 (可选)指定上限集合中允许的最大文档数。 在插入文档时，MongoDB首先检查上限集合 capped 字段的大小，然后检查 max 字段。 没有使用选项的 createCollection() 方法的基本语法如下 MongoDB Enterprise &gt; db.createCollection(&quot;mycollection&quot;) { &quot;ok&quot; : 1 }可以使用命令 show collections 检查创建的集合。 MongoDB Enterprise &gt; show collections mycollection以下示例显示了 createCollection() 方法的语法，其中几个重要选项 MongoDB Enterprise &gt; db.createCollection(&quot;mycol&quot;, {capped : true, autoIndexId : true, size : 6142800, max : 10000 }) { &quot;note&quot; : &quot;the autoIndexId option is deprecated and will be removed in a future release&quot;, &quot;ok&quot; : 1 } note 中说 autoIndexId选项已被弃用，将在以后的版本中删除… 在 MongoDB 中，不需要创建集合。当插入一些文档时，MongoDB 会自动创建集合。 MongoDB Enterprise &gt; db.newcollection.insert({&quot;name&quot; : 123456}) WriteResult({ &quot;nInserted&quot; : 1 }) MongoDB Enterprise &gt; show collections mycol mycollection newcollection删除集合 drop()方法MongoDB 的 db.collection.drop() 用于从数据库中删除集合。 MongoDB Enterprise &gt; show collections mycol mycollection newcollection MongoDB Enterprise &gt; db.newcollection.drop() true MongoDB Enterprise &gt; show collections mycol mycollectionMongoDB支持许多数据类型。 其中一些是 - 字符串 - 这是用于存储数据的最常用的数据类型。MongoDB中的字符串必须为UTF-8。 整型 - 此类型用于存储数值。 整数可以是32位或64位，具体取决于服务器。 布尔类型 - 此类型用于存储布尔值(true / false)值。 双精度浮点数 - 此类型用于存储浮点值。 最小/最大键 - 此类型用于将值与最小和最大BSON元素进行比较。 数组 - 此类型用于将数组或列表或多个值存储到一个键中。 时间戳 - ctimestamp，当文档被修改或添加时，可以方便地进行录制。 对象 - 此数据类型用于嵌入式文档。 Null - 此类型用于存储Null值。 符号 - 该数据类型与字符串相同; 但是，通常保留用于使用特定符号类型的语言。 日期 - 此数据类型用于以UNIX时间格式存储当前日期或时间。您可以通过创建日期对象并将日，月，年的日期进行指定自己需要的日期时间。 对象ID - 此数据类型用于存储文档的ID。 二进制数据 - 此数据类型用于存储二进制数据。 代码 - 此数据类型用于将JavaScript代码存储到文档中。 正则表达式 - 此数据类型用于存储正则表达式。 插入 insert() 方法要将数据插入到 MongoDB 集合中，需要使用 MongoDB 的 insert() 或 save() 方法。 MongoDB Enterprise &gt; db.mycol.insert({ _id : 100, title : &quot;mongoDB&quot;, tags: [&#39;mongdb&#39;, &#39;database&#39;,&#39;nosql&#39;], likes: 10000 }) WriteResult({ &quot;nInserted&quot; : 1 })要插入多个文档，可以在insert()命令中传递文档数组。如下所示 &gt; db.mycol.insert([ { _id: 101, title: &#39;MongoDB Guide&#39;, description: &#39;MongoDB is no sql database&#39;, by: &#39;yiibai tutorials&#39;, url: &#39;http://www.yiibai.com&#39;, tags: [&#39;mongodb&#39;, &#39;database&#39;, &#39;NoSQL&#39;], likes: 100 }, { _id: 102, title: &#39;NoSQL Database&#39;, description: &quot;NoSQL database doesn&#39;t have tables&quot;, by: &#39;yiibai tutorials&#39;, url: &#39;http://www.yiibai.com&#39;, tags: [&#39;mongodb&#39;, &#39;database&#39;, &#39;NoSQL&#39;], likes: 210, comments: [ { user:&#39;user1&#39;, message: &#39;My first comment&#39;, dateCreated: new Date(2017,11,10,2,35), like: 0 } ] }, { _id: 104, title: &#39;Python Quick Guide&#39;, description: &quot;Python Quick start &quot;, by: &#39;yiibai tutorials&#39;, url: &#39;http://www.yiibai.com&#39;, tags: [&#39;Python&#39;, &#39;database&#39;, &#39;NoSQL&#39;], likes: 30, comments: [ { user:&#39;user1&#39;, message: &#39;My first comment&#39;, dateCreated: new Date(2018,11,10,2,35), like: 590 } ] } ])save（document）方法也可以插入document MongoDB Enterprise &gt; db.mycol.save({&quot;save&quot;: &quot;insert&quot;}) WriteResult({ &quot;nInserted&quot; : 1 })其他插入方法 insertOne() db.collection.insertOne() 方法将单个文档插入到集合中。如果文档没有指定_id字段，MongoDB会自动将_id字段与ObjectId值添加到新文档 返回包含新插入的文档的_id （自动生成）字段值的文档。 MongoDB Enterprise &gt; db.mycol.insertOne({&quot;insertOne&quot; : &quot;insert&quot;}) { &quot;acknowledged&quot; : true, &quot;insertedId&quot; : ObjectId(&quot;5de6562157b23a267c05ff5b&quot;) }db.collection.insertMany() 方法将多个文档插入到集合中。如果文档没有指定_id字段，MongoDB会自动将_id字段与ObjectId值添加到新文档 insertMany() 返回包含新插入的文档_id字段值的文档。执行结果如下 &gt; db.inventory.insertMany([ ... { item: &quot;journal&quot;, qty: 25, tags: [&quot;blank&quot;, &quot;red&quot;], size: { h: 14, w: 21, uom: &quot;cm&quot; } }, ... { item: &quot;mat&quot;, qty: 85, tags: [&quot;gray&quot;], size: { h: 27.9, w: 35.5, uom: &quot;cm&quot; } }, ... { item: &quot;mousepad&quot;, qty: 25, tags: [&quot;gel&quot;, &quot;blue&quot;], size: { h: 19, w: 22.85, uom: &quot;cm&quot; } } ... ]) { &quot;acknowledged&quot; : true, &quot;insertedIds&quot; : [ ObjectId(&quot;59552c1c46be576f199feb56&quot;), ObjectId(&quot;59552c1c46be576f199feb57&quot;), ObjectId(&quot;59552c1c46be576f199feb58&quot;) ] }查询文档 drop()方法要从MongoDB集合查询数据，需要使用MongoDB的 find() 方法。 MongoDB Enterprise &gt; db.mycol.find() { &quot;_id&quot; : ObjectId(&quot;5de653e157b23a267c05ff59&quot;) } { &quot;_id&quot; : 100, &quot;title&quot; : &quot;mongoDB&quot;, &quot;tags&quot; : [ &quot;mongdb&quot;, &quot;database&quot;, &quot;nosql&quot; ], &quot;likes&quot; : 10000 } { &quot;_id&quot; : ObjectId(&quot;5de6554957b23a267c05ff5a&quot;), &quot;save&quot; : &quot;insert&quot; } { &quot;_id&quot; : ObjectId(&quot;5de6562157b23a267c05ff5b&quot;), &quot;insertOne&quot; : &quot;insert&quot; }要以格式化的方式显示结果，可以使用 pretty() 方法。 MongoDB Enterprise &gt; db.mycol.find().pretty() { &quot;_id&quot; : ObjectId(&quot;5de653e157b23a267c05ff59&quot;) } { &quot;_id&quot; : 100, &quot;title&quot; : &quot;mongoDB&quot;, &quot;tags&quot; : [ &quot;mongdb&quot;, &quot;database&quot;, &quot;nosql&quot; ], &quot;likes&quot; : 10000 } { &quot;_id&quot; : ObjectId(&quot;5de6554957b23a267c05ff5a&quot;), &quot;save&quot; : &quot;insert&quot; } { &quot;_id&quot; : ObjectId(&quot;5de6562157b23a267c05ff5b&quot;), &quot;insertOne&quot; : &quot;insert&quot; }findOne() 方法，它只返回一个文档。 MongoDB 与 RDBMS的等效 Where 子句find（）方法可加入以下查询条件： 操作 语法 示例 RDBMS等效语句 相等 {:} db.mycol.find({“by”:”yiibai”}).pretty() where by = ‘yiibai’ 小于 {:{$lt:}} db.mycol.find({“likes”:{$lt:50}}).pretty() where likes &lt; 50 小于等于 {:{$lte:}} db.mycol.find({“likes”:{$lte:50}}).pretty() where likes &lt;= 50 大于 {:{$gt:}} db.mycol.find({“likes”:{$gt:50}}).pretty() where likes &gt; 50 大于等于 {:{$gte:}} db.mycol.find({“likes”:{$gte:50}}).pretty() where likes &gt;= 50 不等于 {:{$ne:}} db.mycol.find({“likes”:{$ne:50}}).pretty() where likes != 50 // 查看集合中所有document MongoDB Enterprise &gt; db.mycol.find() { &quot;_id&quot; : ObjectId(&quot;5de7037d4a6c9f4d1af45d7b&quot;) } { &quot;_id&quot; : ObjectId(&quot;5de7039f4a6c9f4d1af45d7c&quot;), &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de703ab4a6c9f4d1af45d7d&quot;), &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 24 } { &quot;_id&quot; : ObjectId(&quot;5de703b64a6c9f4d1af45d7e&quot;), &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 25 } { &quot;_id&quot; : ObjectId(&quot;5de703c14a6c9f4d1af45d7f&quot;), &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 26 } // 等于 MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;:23}) { &quot;_id&quot; : ObjectId(&quot;5de7039f4a6c9f4d1af45d7c&quot;), &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 23 } MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;:23}).pretty() { &quot;_id&quot; : ObjectId(&quot;5de7039f4a6c9f4d1af45d7c&quot;), &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 23 } // 小于、小于等于、大于、大于等于、不等于 MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;:{$lt : 25}}) { &quot;_id&quot; : ObjectId(&quot;5de7039f4a6c9f4d1af45d7c&quot;), &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de703ab4a6c9f4d1af45d7d&quot;), &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 24 } MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;:{$lte : 25}}) { &quot;_id&quot; : ObjectId(&quot;5de7039f4a6c9f4d1af45d7c&quot;), &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de703ab4a6c9f4d1af45d7d&quot;), &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 24 } { &quot;_id&quot; : ObjectId(&quot;5de703b64a6c9f4d1af45d7e&quot;), &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 25 } MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;:{$gt : 25}}) { &quot;_id&quot; : ObjectId(&quot;5de703c14a6c9f4d1af45d7f&quot;), &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 26 } MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;:{$gte : 25}}) { &quot;_id&quot; : ObjectId(&quot;5de703b64a6c9f4d1af45d7e&quot;), &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 25 } { &quot;_id&quot; : ObjectId(&quot;5de703c14a6c9f4d1af45d7f&quot;), &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 26 } MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;:{$ne : 25}}) { &quot;_id&quot; : ObjectId(&quot;5de7037d4a6c9f4d1af45d7b&quot;) } { &quot;_id&quot; : ObjectId(&quot;5de7039f4a6c9f4d1af45d7c&quot;), &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de703ab4a6c9f4d1af45d7d&quot;), &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 24 } { &quot;_id&quot; : ObjectId(&quot;5de703c14a6c9f4d1af45d7f&quot;), &quot;name&quot; : &quot;zhaoliu&quot;, &quot;age&quot; : 26 }MongoDB中的AND操作符在find()方法中，如果通过使用‘ , ’（逗号）将它们分开传递多个键，则 MongoDB 将其视为 AND 条件。 语法： &gt;db.mycol.find( { $and: [ {key1: value1}, {key2:value2} ] } ).pretty()示例： MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;: 23}) { &quot;_id&quot; : ObjectId(&quot;5de7039f4a6c9f4d1af45d7c&quot;), &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de7065c4a6c9f4d1af45d80&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de706634a6c9f4d1af45d81&quot;), &quot;name&quot; : &quot;xiaozhu&quot;, &quot;age&quot; : 23 } MongoDB Enterprise &gt; db.mycol.find({$and:[{&quot;name&quot;:&quot;xiaoming&quot;},{&quot;age&quot;:23}]}) { &quot;_id&quot; : ObjectId(&quot;5de7065c4a6c9f4d1af45d80&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 23 } MongoDB Enterprise &gt; db.mycol.find({&quot;name&quot;:&quot;xiaoming&quot;,&quot;age&quot;:23}) { &quot;_id&quot; : ObjectId(&quot;5de7065c4a6c9f4d1af45d80&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 23 }可以在find子句中传递任意数量的键值。 MongoDB中的OR操作符在要根据 OR 条件查询文档，需要使用 $or 关键字。 语法： &gt;db.mycol.find( { $or: [ {key1: value1}, {key2:value2} ] } ).pretty()示例： // 查询 年龄等于24 或者名字等于wangwu MongoDB Enterprise &gt; db.mycol.find({$or:[{&quot;age&quot; : 24}, {&quot;name&quot;: &quot;wangwu&quot;}]}).pretty() { &quot;_id&quot; : ObjectId(&quot;5de703ab4a6c9f4d1af45d7d&quot;), &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 24 } { &quot;_id&quot; : ObjectId(&quot;5de703b64a6c9f4d1af45d7e&quot;), &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 25 } // 查询 年龄小于24 或者名字等于wangwu MongoDB Enterprise &gt; db.mycol.find({$or:[{&quot;age&quot; : {$lt: 24}}, {&quot;name&quot;: &quot;wangwu&quot;}]}).pretty() { &quot;_id&quot; : ObjectId(&quot;5de7039f4a6c9f4d1af45d7c&quot;), &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de703b64a6c9f4d1af45d7e&quot;), &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 25 } { &quot;_id&quot; : ObjectId(&quot;5de7065c4a6c9f4d1af45d80&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de706634a6c9f4d1af45d81&quot;), &quot;name&quot; : &quot;xiaozhu&quot;, &quot;age&quot; : 23 }使用 AND 和 OR 条件一起// 查询 年龄小于24 并且名字要等于xiaoming或者xiaozhu的用户 MongoDB Enterprise &gt; db.mycol.find({&quot;age&quot;:{$lt : 24}, $or: [{&quot;name&quot; : &quot;xiaoming&quot;},{&quot;name&quot;: &quot;xiaozhu&quot;}]}) { &quot;_id&quot; : ObjectId(&quot;5de7065c4a6c9f4d1af45d80&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 23 } { &quot;_id&quot; : ObjectId(&quot;5de706634a6c9f4d1af45d81&quot;), &quot;name&quot; : &quot;xiaozhu&quot;, &quot;age&quot; : 23 }示例中的查询条件相当于： SELECT * FROM mycol where age &lt; 24 AND (name = ‘xiaoming’ or name = ‘xiaozhu’) 查询嵌入/嵌套文档为方便演示，插入以下内容： db.inventory.insertMany( [ { item: &quot;journal&quot;, qty: 25, size: { h: 14, w: 21, uom: &quot;cm&quot; }, status: &quot;A&quot; }, { item: &quot;notebook&quot;, qty: 50, size: { h: 8.5, w: 11, uom: &quot;in&quot; }, status: &quot;A&quot; }, { item: &quot;paper&quot;, qty: 100, size: { h: 8.5, w: 11, uom: &quot;in&quot; }, status: &quot;D&quot; }, { item: &quot;planner&quot;, qty: 75, size: { h: 22.85, w: 30, uom: &quot;cm&quot; }, status: &quot;D&quot; }, { item: &quot;postcard&quot;, qty: 45, size: { h: 10, w: 15.25, uom: &quot;cm&quot; }, status: &quot;A&quot; } ]);匹配嵌入/嵌套文档要在作为嵌入/嵌套文档的字段上指定相等条件，请使用查询过滤器文档 {&lt;field&gt;：&lt;value&gt;} ，其中 &lt;value&gt; 是要匹配的文档。 查询选择字段size等于{ h: 14, w: 21, uom: “cm” }的所有文档： MongoDB Enterprise &gt; db.inventory.find({size: {h:14, w:21, uom: &quot;cm&quot;}}).pretty() { &quot;_id&quot; : ObjectId(&quot;5de71b8e4a6c9f4d1af45d82&quot;), &quot;item&quot; : &quot;journal&quot;, &quot;qty&quot; : 25, &quot;size&quot; : { &quot;h&quot; : 14, &quot;w&quot; : 21, &quot;uom&quot; : &quot;cm&quot; }, &quot;status&quot; : &quot;A&quot; }整个嵌入式文档中的相等匹配需要精确匹配指定的 &lt;value&gt; 文档，包括字段顺序。 查询嵌套字段要在嵌入/嵌套文档中的字段上指定查询条件，请使用点(.)符号(“ field.nestedField ”)。 以下示例选择在 size 字段中嵌套的字段 uom 等于“ in ”的所有文档： MongoDB Enterprise &gt; db.inventory.find({&quot;size.uom&quot;: &quot;in&quot;}).pretty() { &quot;_id&quot; : ObjectId(&quot;5de71b8e4a6c9f4d1af45d83&quot;), &quot;item&quot; : &quot;notebook&quot;, &quot;qty&quot; : 50, &quot;size&quot; : { &quot;h&quot; : 8.5, &quot;w&quot; : 11, &quot;uom&quot; : &quot;in&quot; }, &quot;status&quot; : &quot;A&quot; } { &quot;_id&quot; : ObjectId(&quot;5de71b8e4a6c9f4d1af45d84&quot;), &quot;item&quot; : &quot;paper&quot;, &quot;qty&quot; : 100, &quot;size&quot; : { &quot;h&quot; : 8.5, &quot;w&quot; : 11, &quot;uom&quot; : &quot;in&quot; }, &quot;status&quot; : &quot;D&quot; }使用查询运算符指定匹配查询过滤器文档可以使用查询运算符来指定，如以下形式的条件: 以下查询使用 size 字段中嵌入的字段 h 中的小于运算符( $lt )： db.inventory.find({&quot;size.h&quot; : { $lt: 15}}) { &quot;_id&quot; : ObjectId(&quot;5de71b8e4a6c9f4d1af45d82&quot;), &quot;item&quot; : &quot;journal&quot;, &quot;qty&quot; : 25, &quot;size&quot; : { &quot;h&quot; : 14, &quot;w&quot; : 21, &quot;uom&quot; : &quot;cm&quot; }, &quot;status&quot; : &quot;A&quot; } { &quot;_id&quot; : ObjectId(&quot;5de71b8e4a6c9f4d1af45d83&quot;), &quot;item&quot; : &quot;notebook&quot;, &quot;qty&quot; : 50, &quot;size&quot; : { &quot;h&quot; : 8.5, &quot;w&quot; : 11, &quot;uom&quot; : &quot;in&quot; }, &quot;status&quot; : &quot;A&quot; } { &quot;_id&quot; : ObjectId(&quot;5de71b8e4a6c9f4d1af45d84&quot;), &quot;item&quot; : &quot;paper&quot;, &quot;qty&quot; : 100, &quot;size&quot; : { &quot;h&quot; : 8.5, &quot;w&quot; : 11, &quot;uom&quot; : &quot;in&quot; }, &quot;status&quot; : &quot;D&quot; } { &quot;_id&quot; : ObjectId(&quot;5de71b8e4a6c9f4d1af45d86&quot;), &quot;item&quot; : &quot;postcard&quot;, &quot;qty&quot; : 45, &quot;size&quot; : { &quot;h&quot; : 10, &quot;w&quot; : 15.25, &quot;uom&quot; : &quot;cm&quot; }, &quot;status&quot; : &quot;A&quot; }指定AND条件以下查询选择嵌套字段 h 小于 15 的所有文档，并且嵌套字段 uom 等于“ in ”，并且 status 字段等于“ D ”： MongoDB Enterprise &gt; db.inventory.find({&quot;size.h&quot; : {$lt : 15}, &quot;size.uom&quot;: &quot;in&quot;, status:&quot;D&quot;}).pretty() { &quot;_id&quot; : ObjectId(&quot;5de71b8e4a6c9f4d1af45d84&quot;), &quot;item&quot; : &quot;paper&quot;, &quot;qty&quot; : 100, &quot;size&quot; : { &quot;h&quot; : 8.5, &quot;w&quot; : 11, &quot;uom&quot; : &quot;in&quot; }, &quot;status&quot; : &quot;D&quot; } 参考资料： 这个网站不错，推荐给大家： 易百教程","categories":[],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://brucy.cn/tags/MongoDB/"}],"keywords":[]},{"title":"MongoDB介绍","slug":"MongoDB介绍","date":"2019-12-03T12:42:51.000Z","updated":"2019-12-03T12:44:14.198Z","comments":true,"path":"2019/12/03/MongoDB介绍/","link":"","permalink":"http://brucy.cn/2019/12/03/MongoDB介绍/","excerpt":"","text":"什么是MongoDB?MongoDB是由MongoDB Inc.开发的开源数据库。MongoDB将数据存储在类似 JSON 的文档中，并且文档中每个json串结构可能有所不同。相关信息存储在一起，通过MongoDB查询语言进行快速查询访问。 MongoDB使用动态模式，这意味着您可以在不首先定义结构的情况下创建记录，例如字段或其值的类型。您可以通过添加新字段或删除现有记录来更改记录的结构（我们称之为文档）。 该数据模型可以让您轻松地代表层次关系，存储数组和其他更复杂的结构。集合中的文档不需要具有相同的一组字段，数据的非规范化是常见的。 MongoDB还设计了高可用性和可扩展性，并提供了即用型复制和自动分片功能。 MongoDB的优势： 更快地构建应用程序，处理高度多样化的数据类型，并更有效地管理应用程序 简化了开发，因为MongoDB文档自然映射到现代的面向对象编程语言。使用MongoDB可以避免将代码中的对象转换为关系表的复杂对象关系映射（ORM）层。 MongoDB的灵活数据模型也意味着您的数据库模式可以随业务需求而发展 MongoDB还可以在多个分布式数据中心之间进行扩展，提供以前MySQL等关系数据库无法实现的新的可用性和可扩展性。随着在数据量和吞吐量方面的增长，MongoDB可轻松扩展，无需停机，无需更改应用程序 下面列出的是MongoDB的一些重要功能特性： 支持特别查询 在MongoDB中，可以通过字段，范围查询进行搜索，并且还支持正则表达式搜索。 索引 可以索引文档中的任何字段。 复制 MongoDB支持主从复制。主机可以执行读写操作，从机从主机复制数据，只能用于读取或备份(不写入) 复制数据 MongoDB可以在多台服务器上运行。 复制数据以保持系统正常运行，并在硬件故障的情况下保持其运行状态。 负载均衡 由于数据放在碎片中，因此具有自动负载平衡配置。 支持映射缩减和聚合工具 使用JavaScript而不是Procedure 它是一个用C++编写的无模式数据库 提供高性能 轻松存储任何大小的文件，而不会使您的堆栈复杂化 在故障的情况下易于管理 它还支持： 具有动态模式的JSON数据模型 自动分片用于水平可扩展性 内置复制高可用性 MongoDB和RDBMS的性能分析在关系数据库(RDBMS)中，表用作存储元素，而在 MongoDB 中使用的是集合。在RDBMS中有多个模式，在每个模式中，可创建用于存储数据的表，而 MongoDB 是面向文档的数据库，数据是以类似JSON格式的BSON格式编写的存储的。MongoDB几乎比传统数据库系统快100倍。 MongoDB和MySQL能否一块使用？MongoDB和MySQL的混合部署有很多例子。在某些情况下，这是一个使用合适工具的的问题。例如，许多电子商务应用程序使用MongoDB和MySQL的组合。产品目录包括具有不同属性的多个产品，非常适合MongoDB的灵活数据模型。另一方面，需要复杂事务的结帐系统可能建立在MySQL或其他关系数据库技术上。 在其他情况下，新的业务需求推动企业采用MongoDB作为其应用程序的下一代组件。例如，世界领先的业务管理软件和服务供应商之一的Sage集团将MongoDB整合到其适用于中型企业的受欢迎的企业资源规划（ERP）解决方案中。 Sage客户现在享受更高程度的功能和个性化作为一体化的结果。虽然许多Sage产品最初建立在MySQL上并继续运行，但最新的用户体验功能集中在MongoDB周围。除了这几个例外，我们认为，由于其灵活的数据模型和可扩展架构，MongoDB几乎总是比MySQL更好的选择。 参考资料： MongoDB与MySQL对比 MongoDB入门","categories":[],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://brucy.cn/tags/MongoDB/"}],"keywords":[]},{"title":"消息队列入门","slug":"消息队列入门","date":"2019-12-01T13:42:36.000Z","updated":"2019-12-07T13:08:04.063Z","comments":true,"path":"2019/12/01/消息队列入门/","link":"","permalink":"http://brucy.cn/2019/12/01/消息队列入门/","excerpt":"","text":"MQ简介在介绍RabbitMQ之前实现要介绍一下MQ，MQ是什么？ MQ全称是Message Queue，可以理解为消息队列的意思，简单来说就是消息以管道的方式进行传递。 RabbitMQ是一个实现了 AMQP（Advanced Message Queuing Protocol） 高级消息队列协议的消息队列服务，底层是用Erlang语言编写的。 使用场景在我们秒杀抢购商品的时候，系统会提醒我们稍等排队中，而不是像几年前一样页面卡死或报错给用户。 像这种排队结算就用到了消息队列机制，放入通道里面一个一个结算处理，而不是某个时间断突然涌入大批量的查询新增把数据库给搞宕机，所以RabbitMQ本质上起到的作用就是削峰填谷，为业务保驾护航。 为什么要使用消息队列？ 解耦：一个系统或一个模块，调用了多个系统或模块；相互之间的调用很复杂，维护起来也很麻烦。但是其实这些调用是不需要直接同步调用接口的。可用MQ实现异步化解耦。 异步：避免多个消息串行执行。提高系统响应速度。 削锋：用消息队列积压大量请求，在后台延迟处理，减缓了数据库的瞬时压力。 消息队列的缺点 整个系统的可用性降低（若MQ故障，整个系统就不能用了） 系统复杂度变高（可能导致消息重复、丢失、积压等情况） 一致性问题（消息消费者可能未正确执行，但消息发布者给用户返回成功） 比较ActiveMQ、RabbitMQ、Kafka 特性 ActiveMQ RabbitMQ RocketMQ Kafka 开发语言 Java Erlang Java Scala 单机吞吐量 万级 万级 十万级 十万级 可用性 高（主从架构） 高（主从架构） 非常高（分布式架构） 非常高（分布式架构） 功能特性 产品成熟；有较多文档支持多种协议；社区不活跃 并发能力很强，性能高；管理界面易用；社区活跃 阿里开源；功能完备；扩展性好 只支持主要的MQ功能，功能比较少；可任意扩展，大数据领域应用广 更详细的对比见文章末尾链接。 工作机制生产者、消费者和代理在了解消息通讯之前首先要了解3个概念：生产者、消费者和代理。 生产者：消息的创建者，负责创建和推送数据到消息服务器； 消费者：消息的接收方，用于处理数据和确认消息； 代理：就是RabbitMQ本身，用于扮演“快递”的角色，本身不生产消息，只是扮演“快递”的角色。 消息发送原理首先你必须连接到Rabbit才能发布和消费消息，那怎么连接和发送消息的呢？ 你的应用程序和Rabbit Server之间会创建一个TCP连接，一旦TCP打开，并通过了认证，认证就是你试图连接Rabbit之前发送的Rabbit服务器连接信息和用户名和密码，有点像程序连接数据库，使用Java有两种连接认证的方式，后面代码会详细介绍，一旦认证通过你的应用程序和Rabbit就创建了一条AMQP信道（Channel）。 信道是创建在“真实”TCP上的虚拟连接，AMQP命令都是通过信道发送出去的，每个信道都会有一个唯一的ID，不论是发布消息，订阅队列或者介绍消息都是通过信道完成的。 为什么不通过TCP直接发送命令？对于操作系统来说创建和销毁TCP会话是非常昂贵的开销，假设高峰期每秒有成千上万条连接，每个连接都要创建一条TCP会话，这就造成了TCP连接的巨大浪费，而且操作系统每秒能创建的TCP也是有限的，因此很快就会遇到系统瓶颈。 如果我们每个请求都使用一条TCP连接，既满足了性能的需要，又能确保每个连接的私密性，这就是引入信道概念的原因。 参考文章ActiveMQ、RabbitMQ、Kafka对比王磊的博客","categories":[],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://brucy.cn/tags/消息队列/"}],"keywords":[]},{"title":"使用volatile修饰基本数据内存不能保证原子性","slug":"使用volatile修饰基本数据内存不能保证原子性","date":"2019-11-24T09:44:23.000Z","updated":"2019-11-24T09:44:52.948Z","comments":true,"path":"2019/11/24/使用volatile修饰基本数据内存不能保证原子性/","link":"","permalink":"http://brucy.cn/2019/11/24/使用volatile修饰基本数据内存不能保证原子性/","excerpt":"","text":"对synchronized 的探究先来看最初始的代码，两个线程不共享数据i的情况： package exampleTest; public class synText { public static void main(String[] args) { myTest my1 = new myTest(&quot;线程1：&quot;); Thread thread1 = new Thread(my1); myTest my2 = new myTest(&quot;线程%%%%2：&quot;); Thread thread2 = new Thread(my2); thread1.start(); thread2.start(); } } class myTest implements Runnable { String name; public myTest(String name) { this.name = name; } @Override public void run() { new test().count(this.name); } } class test { int j = 0; public void count(String name) { for (int i = 0; i &lt; 100000; i++) { System.out.println(name + &quot;--------&gt;&quot; + j++); } } } 执行结果：两个线程没有共享的数据域，两线程交替执行，互不干扰，都加到了99999； 在count方法上加synchronized关键字对count方法稍作改动，其他部分的代码不改动: class test { static int j = 0; public synchronized void count(String name) { for (int i = 0; i &lt; 100000; i++) { System.out.println(name + &quot;--------&gt;&quot; + j++); } } } 执行结果：两线程交替执行，两线程互相干扰 ，多次执行结果不同 因为 j 被static修饰，所以两个线程会共享资源j；造成了在j++执行时读写不一致synchronized 关键字加在方法上没什么效果 class test { static volatile int j = 0; public void count(String name) { for (int i = 0; i &lt; 100000; i++) { System.out.println(name + &quot;--------&gt;&quot; + j++); } } } 执行结果：多次执行结果不同，没有同步 volatile，保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 但为什么 j 没有同步呢？这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量j的值为10， 线程1对变量进行自增操作，线程1先读取了变量j的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量j的原始值，由于线程1只是对变量j进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量j的缓存行无效，所以线程2会直接去主存读取j的值，发现j的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了j的值，注意此时在线程1的工作内存中j的值仍然为10，所以线程1对j进行加1操作后j的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，j只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，==线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改==。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 这是因为虽然 volatile 保证了内存可见性，每个线程拿到的值都是最新值，但 j++ 这个操作并不是原子的，这里面涉及到获取值、自增、赋值的操作并不能同时完成。 部分内容截取自，https://www.cnblogs.com/dolphin0520/p/3920373.html 总而言之，volatile可以保证在一个线程修改了其线程内存中的值就立刻写回主存中，但是 这样可以成功加锁class test { static int j = 0; public void count(String name) { for (int i = 0; i &lt; 100000; i++) { synchronized (test.class) { j++; } System.out.println(name + &quot;--------&gt;&quot; + j); } } }","categories":[],"tags":[],"keywords":[]},{"title":"volatile关键字解析","slug":"volatile关键字解析","date":"2019-11-23T12:53:22.000Z","updated":"2019-11-23T12:53:55.892Z","comments":true,"path":"2019/11/23/volatile关键字解析/","link":"","permalink":"http://brucy.cn/2019/11/23/volatile关键字解析/","excerpt":"","text":"并发编程中的三个概念 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 可见性：可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性：即程序执行的顺序按照代码的先后顺序执行。 指令重排序（Instruction Reorder），处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 Java内存模型 在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 举个简单的例子：在java中，执行下面这个语句： i = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。 那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？ 1. 原子性 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i： 请分析以下哪些操作是原子性操作： x = 10; //语句1 y = x; //语句2 x++; //语句3 x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 2. 可见性 对于可见性，Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 3.有序性 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 这8条原则摘自《深入理解Java虚拟机》。 这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。 下面我们来解释一下前4条规则： 对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 深入剖析volatile关键字volatile关键字的两层语义： 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 禁止进行指令重排序。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 本文截取自 https://www.cnblogs.com/dolphin0520/p/3920373.html","categories":[],"tags":[],"keywords":[]},{"title":"MyBatis数据源与连接池","slug":"MyBatis数据源与连接池","date":"2019-11-18T12:52:56.000Z","updated":"2019-11-18T12:55:01.647Z","comments":true,"path":"2019/11/18/MyBatis数据源与连接池/","link":"","permalink":"http://brucy.cn/2019/11/18/MyBatis数据源与连接池/","excerpt":"","text":"MyBatis 把数据源 DataSource 分为三种： UNPOOLED 不使用连接池的数据源 POOLED 使用连接池的数据源 JNDI（Java Naming and Directory Interface ） 使用 JNDI 实现的数据源 创建数据源MyBatis 是通过工厂模式来创建数据源 DataSource 对象的，MyBatis 定义了抽象的工厂接口:org.apache.ibatis.datasource.DataSourceFactory,通过其 getDataSource()方法返回数据源DataSource。上述三种不同类型的 type，则有对应的以下 dataSource 工厂： POOLED PooledDataSourceFactory UNPOOLED UnpooledDataSourceFactory JNDI JndiDataSourceFactory Connection 创建当我们需要创建 SqlSession 对象并需要执行 SQL 语句时，这时候 MyBatis 才会去调用dataSource 对象来创建 java.sql.Connection 对象。也就是说，java.sql.Connection 对象的创建一直延迟到执行 SQL 语句的时候 Unpooled当 的 type 属性被配置成了”UNPOOLED”，MyBatis 首先会实例化一个UnpooledDataSourceFactory 工 厂 实 例 ， 然 后 通 过 .getDataSource() 方 法 返 回 一 个UnpooledDataSource 实例对象引用，我们假定为 dataSource。使用 UnpooledDataSource 的 getConnection(),每调用一次就会产生一个新的 Connection 实例对象。UnpooledDataSource 会做以下事情： 初始化驱动：判断 driver 驱动是否已经加载到内存中，如果还没有加载，则会动态地加载 driver 类，并实例化一个 Driver 对象，使用 DriverManager.registerDriver()方法将其注册到内存中，以供后续使用。 创建 Connection 对象：使用 DriverManager.getConnection()方法创建连接。 配置 Connection 对象：设置是否自动提交 autoCommit 和隔离级别 isolationLevel。 返回 Connection 对象。 PooledPooledDataSource 将 java.sql.Connection 对 象 包 裹 成 PooledConnection 对 象 放 到 了PoolState 类型的容器中维护。MyBatis 将连接池中的 PooledConnection 分为两种状态： 空闲状态（idle） 和 活动状态(active)，这两种状态的 PooledConnection 对象分别被存储到PoolState 容器内的 idleConnections 和 activeConnections 两个 List 集合中： idleConnections:空闲(idle)状态 PooledConnection 对象被放置到此集合中，表示当前闲置的没有被使用的 PooledConnection 集合，调用 PooledDataSource 的 getConnection()方法时，会优先从此集合中取 PooledConnection 对象。当用完一个 java.sql.Connection 对象时，MyBatis 会将其包裹成 PooledConnection 对象放到此集合中。 activeConnections:活 动 (active) 状 态 的 PooledConnection 对 象 被 放 置 到 名 为activeConnections 的 ArrayList 中，表示当前正在被使用的 PooledConnection 集合，调用PooledDataSource 的 getConnection() 方 法 时 ， 会 优 先 从 idleConnections 集 合 中 取 PooledConnection 对象,如果没有，则看activeConnections集合是否已满，如果未满，PooledDataSource 会创建出一个 PooledConnection，添加到此集合中，并返回。 popConnection()方法到底做了什么： 先看是否有空闲(idle)状态下的 PooledConnection 对象，如果有，就直接返回一个可用的 PooledConnection 对象；否则进行第 2 步。 查看活动状态的 PooledConnection 池 activeConnections 是否已满；如果没有满，则创建一个新的 PooledConnection 对象，然后放到 activeConnections 池中，然后返回此PooledConnection 对象；否则进行第三步； 看最先进入 activeConnections 池中的 PooledConnection 对象是否已经过期：如果已经过期，从 activeConnections 池中移除此对象，然后创建一个新的 PooledConnection 对象，添加到 activeConnections 中，然后将此对象返回；否则进行第 4 步。 线程等待 当我们的程序中使用完 Connection 对象时，如果不使用数据库连接池，我们一般会调用connection.close()方法，关闭 connection 连接，释放资源。我们希望当 Connection 使用完后，调用.close()方法，而实际上 Connection 资源并没有被释放，而实际上被添加到了连接池中。这里要使用代理模式，为真正的 Connection 对象创建一个代理对象，代理对象所有的方法都是调用相应的真正 Connection 对象的方法实现。当代理对象执行 close()方法时，要特殊处理，不调用真正 Connection 对象的 close()方法，而是将 Connection 对象添加到连接池中。MyBatis 的 PooledDataSource 的 PoolState 内部维护的对象是 PooledConnection 类型的对象，而 PooledConnection 则是对真正的数据库连接 java.sql.Connection 实例对象的包裹器。PooledConenction 实现了 InvocationHandler 接口，并且 proxyConnection 对象也是根据这它来生成的代理对象。","categories":[],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://brucy.cn/tags/MyBatis/"}],"keywords":[]},{"title":"Spring注解驱动编程","slug":"Spring注解驱动编程","date":"2019-11-17T02:41:25.000Z","updated":"2019-11-17T03:24:28.935Z","comments":true,"path":"2019/11/17/Spring注解驱动编程/","link":"","permalink":"http://brucy.cn/2019/11/17/Spring注解驱动编程/","excerpt":"","text":"注解的派生性注解有派生性：在SpringFramework 4.0 中通过递归的方式查找元注解，实现了注解的派生性；在3.0 支持两层继承；在2.0中支持单继承 派生性导致了覆盖：在Spring中，由于注解的查找方式（递归查找），底层（对比子类理解）注解可以覆盖高层（对比超类理解）注解的同名属性。 注意：在Java 编程语言级别上，Java注解是绝对静态性的，且属性方法是表达注解状态的唯一途径。并且注解是不可继承或实现的。上文所说的派生性是指Spring层面上，由于Spring中注解的查找方式（递归查找）而产生的派生性。 Spring中注解分类元注解（Meta-Annotations）： 指能声明在其他注解上的注解，在java中元注解有@Document、@Repeatable等，在Spring使用场景中，元注解有@Component等 Spring模式注解（Stereotype Annotations）： 用来表明组件在应用中扮演什么角色的注解， 比如@Repository作为仓储标记注解，管理和存储某种领域的对象。（注解有派生性） Spring 组合注解（Composed Annotations）： 指某个注解“元标注”（被标注）一个或多个其他注解，其目的在于将这些关联的注解行为组合成单个自定义注解。比如：@TransactionalService 注解标注了 @Transactional 和 @Service注解，因此@TransactionalService注解组合了这两个注解的语义。 @Transactional 是个元注解，是Spring事务注解； @Service 是Spring模式注解，被@Component标注 Spring 注解属性别名和覆盖（Attribute Aliases and Override）: String Framework 为Spring 元注解和@AliasFor 提供了属性覆盖和别名的特性。实现了属性值在注解结构中的传递行为。 @AliasFor显性别名：在同一注解中的两个属性方法相互标注@AliasFor，且这两个属性方法的默认值必须相同，这样的行为称为显性别名。 隐形别名：如@TransactionalService这样的注解，通过注解属性方法name（）和value()相互“@AliasFor”，并且value（）又覆盖了@service.value（）属性，因此@TransactionalService.name()与@Service.value（）之间的关系被称为“隐性别名”。 不同层次注解属性之间也可通过@AliasFor设置别名 public @interface SpringBootApplication { @AliasFor( annotation = EnableAutoConfiguration.class ) Class&lt;?&gt;[] exclude() default {}; ... }例如：@SpringBootApplication 在exclude（）属性上与其元注解@EnableAutoConfiguration建立了单向@AliasFor关系。如果反向建立关系，是不合理的，Spring元注解之间不应该相互元标注。简而言之，多层次注解属性之间的@AliasFor 关系只能由较低层向较高层建立。 读《Spring Boot 编程思想（核心篇）》部分章节内容总结","categories":[],"tags":[],"keywords":[]},{"title":"归并排序（递归）","slug":"归并排序（递归）","date":"2019-11-16T05:03:54.000Z","updated":"2019-11-16T05:09:22.889Z","comments":true,"path":"2019/11/16/归并排序（递归）/","link":"","permalink":"http://brucy.cn/2019/11/16/归并排序（递归）/","excerpt":"","text":"title: 归并排序date: 2019-10-26 10:56:30tags: 算法 归并排序归并排序对分治思想的典型应用。归并排序的总体思路是==先拆分数组再按正确顺序合并数组==。 合并步骤： 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列 设定两个指针，最初位置分别为两个已经排序序列的起始位置 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置 重复步骤3直到某一指针超出序列尾 将另一序列剩下的所有元素直接复制到合并序列尾 利用递归实现的java代码：public static void mergeSort(int[] arr) { if (arr == null || arr.length &lt; 2) { return; } mergeSort(arr, 0, arr.length - 1); } // 拆分 public static void mergeSort(int[] arr, int l, int r) { if (l == r) { return; } int mid = l + ((r - l) &gt;&gt; 1); // 这里相当于（l + r）/ 2 , 这样写可防止溢出，加快计算速度 mergeSort(arr, l, mid); mergeSort(arr, mid + 1, r); merge(arr, l, mid, r); } // 合并 public static void merge(int[] arr, int l, int mid, int r) { int[] help = new int[r - l + 1]; int i = 0; // 2个指针 int p1 = l; int p2 = mid + 1; // 排序直到某一指针超出序列尾 while (p1 &lt;= mid &amp;&amp; p2 &lt;= r) { help[i++] = arr[p1] &lt; arr[p2] ? arr[p1++] : arr[p2++]; } // 下面这俩个while每次只有一个能达成执行条件 // 将另一序列剩下的所有元素直接复制到合并序列尾 while (p1 &lt;= mid) { help[i++] = arr[p1++]; } while (p2 &lt;= r) { help[i++] = arr[p2++]; } // help数组已排好序，help 数组覆 arr 数组的相应位置 for (i = 0; i &lt; help.length; i++) { arr[l++] = help[i]; } }归并排序流程图图片来源 复杂度分析时间复杂度 O(N*logN) ，额外空间复杂度 O(N) ，实现 可以做到稳定性 注意: 库函数中排序的实现是综合排序，比如插入+快速；比如为了稳定性， 排序算法往往是快排+堆排序 归并排序和快速排序，都一定存在非递归的实现 归并排序，存在额外空间复杂度O(1)的实现，但是非常难 归并排序的扩展，小和问题，逆序对 C 代码#include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; void Merge(int sourceArr[],int tempArr[], int startIndex, int midIndex, int endIndex) { int i = startIndex, j=midIndex+1, k = startIndex; while(i!=midIndex+1 &amp;&amp; j!=endIndex+1) { if(sourceArr[i] &gt; sourceArr[j]) tempArr[k++] = sourceArr[j++]; else tempArr[k++] = sourceArr[i++]; } while(i != midIndex+1) tempArr[k++] = sourceArr[i++]; while(j != endIndex+1) tempArr[k++] = sourceArr[j++]; for(i=startIndex; i&lt;=endIndex; i++) sourceArr[i] = tempArr[i]; } //内部使用递归 void MergeSort(int sourceArr[], int tempArr[], int startIndex, int endIndex) { int midIndex; if(startIndex &lt; endIndex) { midIndex = startIndex + (endIndex-startIndex) / 2;//避免溢出int MergeSort(sourceArr, tempArr, startIndex, midIndex); MergeSort(sourceArr, tempArr, midIndex+1, endIndex); Merge(sourceArr, tempArr, startIndex, midIndex, endIndex); } } int main(int argc, char * argv[]) { int a[8] = {50, 10, 20, 30, 70, 40, 80, 60}; int i, b[8]; MergeSort(a, b, 0, 7); for(i=0; i&lt;8; i++) printf(&quot;%d &quot;, a[i]); printf(&quot;\\n&quot;); return 0; } 参考资料别人的简书归并排序图解-很简明 别人的博客-很详细","categories":[],"tags":[],"keywords":[]},{"title":"TCP三次握手与四次挥手","slug":"TCP三次握手与四次挥手","date":"2019-11-16T04:59:17.000Z","updated":"2019-11-16T05:00:59.299Z","comments":true,"path":"2019/11/16/TCP三次握手与四次挥手/","link":"","permalink":"http://brucy.cn/2019/11/16/TCP三次握手与四次挥手/","excerpt":"","text":"TCP 概述 TCP是面向连接的运输层协议 每一条TCP连接只能有一个发送端和一个接收端 TCP是提供可靠交付的服务 TCP提供全双工通信 面向字节流 TCP报文标志位 URG ：等于1时，表明此段中有紧急数据，需尽快发送 ACK ：（确认比特）等于1时，表明此报文是一个确认报文 PSH ：等于1时，表示此报文要尽快交给接收进程，不再等接收缓存区填满了再交付 RST ：（复位比特）等于1时，表示TCP连接出现严重错误，需重新建立连接 SYN ：（同步比特）等于1时，表示此报文是一个协商报文不用放入缓存区，报文是连接请求或是连接接收报文，不存放数据。 FIN ：（终止比特）等于1时，表明此报文发送完毕，请求释放连接 建立连接（三次握手） 客户端发送连接请求，同步比特SYN=1，序列号SEQ= x 服务器返回确认，同步比特SYN=1，确认比特ACK=1，序列号SEQ=y, 确认号ack= x+1 客户端返回确认， 确认比特ACK=1， 序列号SEQ=x+1，确认号ack=y+1 释放连接（四次挥手） 主动关闭方请求释放连接：终止比特FIN=1 ， 序列号SEQ = u 被动方确认：确认标志位ACK=1，序列号SEQ = v，确认号ack = u+1 被动方应用进程释放连接，再次发送确认：终止比特FIN=1，确认标志位ACK=1，序列号SEQ = w，确认号ack = u+1 主动方确认关闭：确认标志位ACK=1，序列号SEQ = u+1，确认号ack = w+1 这时还没结束，因为无法确定被动方是否正确收到最后的确认报文，所以主动方需等待2MSL（最大报文生存时间） ，如果由于信道原因被动方未收到最终确认报文，被动方会重发第3次挥手时所发的报文。","categories":[],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://brucy.cn/tags/计算机网络/"}],"keywords":[]},{"title":"类的执行过程","slug":"类的执行过程","date":"2019-11-16T04:58:25.000Z","updated":"2019-11-16T04:58:25.311Z","comments":true,"path":"2019/11/16/类的执行过程/","link":"","permalink":"http://brucy.cn/2019/11/16/类的执行过程/","excerpt":"","text":"","categories":[],"tags":[],"keywords":[]},{"title":"ArrayList源码详解","slug":"ArrayList源码详解","date":"2019-11-13T13:18:41.000Z","updated":"2020-02-11T14:00:33.920Z","comments":true,"path":"2019/11/13/ArrayList源码详解/","link":"","permalink":"http://brucy.cn/2019/11/13/ArrayList源码详解/","excerpt":"","text":"","categories":[{"name":"Java API","slug":"Java-API","permalink":"http://brucy.cn/categories/Java-API/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"http://brucy.cn/tags/ArrayList/"}],"keywords":[{"name":"Java API","slug":"Java-API","permalink":"http://brucy.cn/categories/Java-API/"}]},{"title":"Java8-Lambda表达式与函数式接口","slug":"Java8-Lambda表达式与函数式接口","date":"2019-11-08T06:47:20.000Z","updated":"2019-11-08T06:47:49.392Z","comments":true,"path":"2019/11/08/Java8-Lambda表达式与函数式接口/","link":"","permalink":"http://brucy.cn/2019/11/08/Java8-Lambda表达式与函数式接口/","excerpt":"","text":"Lambda表达式Lambda表达式（也叫做闭包）是Java 8中最大的也是期待已久的变化。它允许我们将一个函数当作方法的参数（传递函数），或者说把代码当作数据，这是每个函数式编程者熟悉的概念。很多基于JVM平台的语言一开始就支持Lambda表达式，但是Java程序员没有选择，只能使用匿名内部类来替代Lambda表达式。 Lambda表达式的设计被讨论了很久，而且花费了很多的功夫来交流。不过最后取得了一个折中的办法，得到了一个新的简明并且紧凑的Lambda表达式结构。最简单的Lambda表达式可以用逗号分隔的参数列表、-&gt;符号和功能语句块来表示。示例如下： Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( e -&gt; System.out.println( e ) );请注意到编译器会根据上下文来推测参数的类型，或者你也可以显示地指定参数类型，只需要将类型包在括号里。举个例子： Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( ( String e ) -&gt; System.out.println( e ) );如果Lambda的功能语句块太复杂，我们可以用大括号包起来，跟普通的Java方法一样，如下： String separator = &quot;,&quot;; Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( ( String e ) -&gt; System.out.print( e + separator ) );Lambda表达式可能会引用类的成员或者局部变量（会被隐式地转变成final类型），下面两种写法的效果是一样的： String separator = &quot;,&quot;; Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( ( String e ) -&gt; System.out.print( e + separator ) );和 final String separator = &quot;,&quot;; Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).forEach( ( String e ) -&gt; System.out.print( e + separator ) );Lambda表达式可能会有返回值，编译器会根据上下文推断返回值的类型。如果lambda的语句块只有一行，不需要return关键字。下面两个写法是等价的： Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).sort( ( e1, e2 ) -&gt; e1.compareTo( e2 ) );和 Arrays.asList( &quot;a&quot;, &quot;b&quot;, &quot;d&quot; ).sort( ( e1, e2 ) -&gt; { int result = e1.compareTo( e2 ); return result; } );函数式接口语言的设计者们思考了很多如何让现有的功能和lambda表达式友好兼容。于是就有了函数接口这个概念。函数接口是一种只有一个抽象方法的接口（contains only one abstract method），像这样地，函数接口可以隐式地转换成lambda表达式。 java.lang.Runnable 和java.util.concurrent.Callable是函数接口两个最好的例子。但是在实践中，函数接口是非常脆弱的，只要有人在接口里添加多一个方法，那么这个接口就不是函数接口了，就会导致编译失败。Java 8提供了一个特殊的注解@FunctionalInterface来克服上面提到的脆弱性并且显示地表明函数接口的目的（java里所有现存的接口都已经加上了@FunctionalInterface）。让我们看看一个简单的函数接口定义： @FunctionalInterface public interface Functional { void method(); }我们要记住默认的方法和静态方法（下一节会具体解释）不会违反函数接口的约定，例子如下： @FunctionalInterface public interface FunctionalDefaultMethods { void method(); default void defaultMethod() { } }支持Lambda是Java 8最大的卖点，他有巨大的潜力吸引越来越多的开发人员转到这个开发平台来，并且在纯Java里提供最新的函数式编程的概念。对于更多的细节，请参考官方文档。 接口的默认方法和静态方法Java 8增加了两个新的概念在接口声明的时候：默认和静态方法。默认方法和Trait有些类似，但是目标不一样。默认方法允许我们在接口里添加新的方法，而不会破坏实现这个接口的已有类的兼容性，也就是说不会强迫实现接口的类实现默认方法。 默认方法和抽象方法的区别是抽象方法必须要被实现，默认方法不是。作为替代方式，接口可以提供一个默认的方法实现，所有这个接口的实现类都会通过继承得倒这个方法（如果有需要也可以重写这个方法），让我们来看看下面的例子： private interface Defaulable { // Interfaces now allow default methods, the implementer may or // may not implement (override) them. default String notRequired() { return &quot;Default implementation&quot;; } } private static class DefaultableImpl implements Defaulable { } private static class OverridableImpl implements Defaulable { @Override public String notRequired() { return &quot;Overridden implementation&quot;; } }接口Defaulable使用default关键字声明了一个默认方法notRequired()，类DefaultableImpl实现了Defaulable接口，没有对默认方法做任何修改。另外一个类OverridableImpl重写类默认实现，提供了自己的实现方法。 Java 8 的另外一个有意思的新特性是接口里可以声明静态方法，并且可以实现。例子如下： private interface DefaulableFactory { // Interfaces now allow static methods static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) { return supplier.get(); } }下面是把接口的静态方法和默认方法放在一起的示例（::new 是构造方法引用，后面会有详细描述）： public static void main( String[] args ) { Defaulable defaulable = DefaulableFactory.create( DefaultableImpl::new ); System.out.println( defaulable.notRequired() ); defaulable = DefaulableFactory.create( OverridableImpl::new ); System.out.println( defaulable.notRequired() ); }控制台的输出如下： Default implementationOverridden implementation JVM平台的接口的默认方法实现是很高效的，并且方法调用的字节码指令支持默认方法。默认方法使已经存在的接口可以修改而不会影响编译的过程。java.util.Collection中添加的额外方法就是最好的例子：stream(), parallelStream(), forEach(), removeIf() 虽然默认方法很强大，但是使用之前一定要仔细考虑是不是真的需要使用默认方法，因为在层级很复杂的情况下很容易引起模糊不清甚至变异错误。更多的详细信息请参考官方文档。 参考文献： 并发编程网 - ifeve.com Java 8 特性 – 终极手册 JAVA8十大新特性详解（精编） 官方文档","categories":[],"tags":[],"keywords":[]},{"title":"设计模式—-创建型模式","slug":"设计模式—-创建型模式","date":"2019-11-06T07:26:46.000Z","updated":"2019-11-06T07:27:31.347Z","comments":true,"path":"2019/11/06/设计模式—-创建型模式/","link":"","permalink":"http://brucy.cn/2019/11/06/设计模式—-创建型模式/","excerpt":"","text":"创建型模式 作用：主要用于创建对象，为类实例化对象提供指南 创建型模式，共五种： 工厂方法模式 抽象工厂模式 建造者模式 原型模式 单例模式 工厂模式对用户屏蔽了生产细节。对生产者而言，使生产者更加专业化，并具有统一管理能力。对消费者而言，消费者不必关心生产过程，只关心产品。多种同类型产品由一个工厂生产，通过工厂提高了对产品的管理能力，并且消费者只与工厂交互。 我们用一个简单的Car类来演示： public class Car { public String name; public Car(String name) { this.name = name; } public String getName() { return name; } public void setName(String name) { this.name = name; } }建一个工厂类，其中getCar方法将返回一个Car实例。 public class Factory { public Car getCar(String name) { return new Car(name); } } 新建一个Factory类，并调用其getCar方法，即可获得一个Car。 public class Test { public static void main(String[] args) { Factory factory = new Factory(); Car car = factory.getCar(&quot;BMW&quot;); System.out.println(car.getName()); } // 控制台输出： BMW }1. 工厂方法模式（Factory Methord）定义一个创建对象的接口，有子类决定需要实例化哪一个类。工厂方法使得子类的实例化过程推迟 在工厂方法模式下：有多个工厂实现一个工厂接口，消费者通过与各个工厂交互得到由更专业的工厂生产的产品。 2. 抽象工厂模式（Abstract Factory）多个工厂实现一个抽象工厂，用户与抽象工厂（或默认工厂）交互，抽象工厂通过调用更专业的工厂来生产产品并返回给用户。抽象工厂中自带分发逻辑，这是与接口工厂不同的。 3. 构建器模式（Builder） 将一个复杂类的表示与其构造相分离，使得相同的构建过程能得到不同的表示，工厂类模式提供的是创建单个类的模式，而建造者模式则是将各种产品集中起来进行管理，用来创建复合对象，所谓复合对象就是指某个类具有不同的属性。 public class Builder { private List&lt;Sender&gt; list = new ArrayList&lt;Sender&gt;(); public void produceMailSender(int count){ for(int i=0; i&lt;count; i++){ list.add(new MailSender()); } } public void produceSmsSender(int count){ for(int i=0; i&lt;count; i++){ list.add(new SmsSender()); } } } 测试类： public class Test { public static void main(String[] args) { Builder builder = new Builder(); builder.produceMailSender(10); } }建造者模式将很多功能集成到一个类里，这个类可以创造出比较复杂的东西。所以与工程模式的区别就是：工厂模式关注的是创建单个产品，而建造者模式则关注创建符合对象，多个部分。因此，是选择工厂模式还是建造者模式，依实际情况而定。 4. 原型模式（Prototype） 用原型实例指定创建对象的类型，并通过copy这个原型来创建新的对象 原型模式虽然是创建型的模式，但是与工程模式没有关系，从名字即可看出，该模式的思想就是将一个对象作为原型，对其进行复制、克隆，产生一个和原对象类似的新对象。 5. 单例模式（Singleton） 保证从系统启动到系统停止，全过程只会生产一个实例，并提供一个访问它的全局访问点。 理解单例模式 ： 比如一个军队出现了多个司令员同时指挥，肯定会乱成一团，所以在一个系统中有些对象只能有一个。 单例模式存在懒汉式与饿汉式两种： 懒汉式：在其他类获取单例对象时才创建该单例对象，可以通过同步加锁的方式保证多次获取单例对象的情况下不会重复创建。 饿汉式：在单例对象加载时就创建一个静态对象，其他类获取次单例对象时直接返回该单例对象，以此来保证单例对象只创建一次。 简单的单例模式的编码方式： public class Singleton { /* 持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 */ private static Singleton instance = null; /* 私有构造方法，防止构造方法被其他类调用从而导致多个单例对象被实例化 */ private Singleton() { } /* 静态工程方法，创建实例 */ public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() { return instance; } } 在多线程的情况下，对getInstance方法加synchronized关键字，但这种方法效率并不高，如下： Public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; }通过双重检查（double checking）的方式在多线程情况下保证对象单例 Public class A{ private static A instance; public static Singleton getInstance() { if (instance == null) { // 第一次检查，为了提高效率 synchronized (instance) { if (instance == null) { // 第二次检查，为了保证安全 instance = new Singleton(); } } } return instance; } }优化：在单例类中创建一个私有静态内部类，该内部类用于创建一个静态单例对象。因为类在被获取时才会被加载，所以在需要获取此单例对象时，才加载内部类创建单例对象。以此来提高效率。 当系统中遇到功能性冲突时，需要使用单例模式。 参考资料一句话理解23种设计模式 Java开发中的23种设计模式详解","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://brucy.cn/tags/设计模式/"}],"keywords":[]},{"title":"设计模式-设计模式的七大原则","slug":"设计模式-设计模式的七大原则","date":"2019-11-06T01:38:47.000Z","updated":"2019-11-06T07:27:40.157Z","comments":true,"path":"2019/11/06/设计模式-设计模式的七大原则/","link":"","permalink":"http://brucy.cn/2019/11/06/设计模式-设计模式的七大原则/","excerpt":"","text":"设计模式的七大原则学习设计模式的建议 别把设计模式想的很复杂，在有一定编程经验后很容易就能理解 学习设计模式重在学习设计思想，灵活使用，不要生搬硬套 永远不变的中心思想————高内聚、低耦合 开闭原则（Open Close Principle）Open-Close Principle（OCP）：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。目的就是保证程序的扩展性好，易于维护和升级。 开闭原则被称为面向对象设计的基石，实际上，其他原则都可以看作是实现开闭原则的工具和手段。意思就是：软件对扩展应该是开放的，对修改是封闭的，通俗来说就是，开发一个软件时，应该对其进行功能扩展，而在进行这些扩展时，不需要对原来的程序进行修改。 好处是：软件可用性非常灵活，扩展性强。需要新的功能时，可以增加新的模块来满足新需求。另外由于原来的模块没有修改，所以不用担心稳定性的问题。 里氏代换原则（Liskov Substitution Principle）里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。 依赖倒转原则（Dependence Inversion Principle）Dependence Inversion Principle（DIP）：是一个类与类之间的调用规则。这里的依赖就是代码中的耦合。高层模块不应该依赖底层模块，二者都应该依赖其抽象了；抽象不依赖细节；细节应该依赖抽象。接口编程。面向接口编程，依赖于抽象而不依赖于具体。 主要思想就是：如果一个类中的一个成员或者参数成为一个具体的类型，那么这个类就依赖这个具体类型。如果在一个继承结构中，上层类中的一个成员或者参数为一个下层类型，那么就是这个继承结构高层依赖底层，就要尽量面向抽象或者接口编程。 举例：存在一个Driver类，成员为一个Car对象，还有一个driver()方法，Car对象中有两个方法start()与stop()。显然Driver依赖Car，也就是说Driver类调用了Car类中的方法。但是当增加Driver类对于Bus类的支持时（司机有需要开公交车），就必须更改Driver中的代码，就破坏了开放封闭原则。根本原因在于高层的的Driver类与底层的Car类紧紧的耦合在一起。解决方法之一就是：对Car类和Bus类进行抽象，引入抽象类Automoble。而Car和Bus则是对Automobile的泛化。 经过这样的改造发现，原本的高层依赖底层，变成了高层与底层同时依赖抽象。这就是依赖倒转原则的本质。 单一职责原则（Single-Responsibilitiy Principle）Single-Responsibilitiy Principle（SRP）：对一个类而言，应该仅有一个引起它变化的原因。如果存在多于一个动机去改变一个类，那么这个类就具有多于一个的职责，就应该把多余的职责分离出去，再去创建一些类来完成每一个职责。设计目的单一的类。也就是降低程序的耦和程度 举个例子：一个人身兼数职，而这些事情相关性不大，甚至有冲突，那他就无法很好的解决这些问题职责，应该分到不同的人身上去做。单一职责原则是实现高内聚低耦合的最好方法，没有之一。 class CellPhone： def call（string person）： //打电话 pass def hangup（）： //挂断电话 pass def sendMessage（string person）： //发送信息 pass def receiveMessage(): //接受信息 pass上面的手机类虽然符合人们对手机的认识，但是实际上却拥有两个不同的职责：打电话、挂断电话和发短信、接受信息，因此引起它变化的原因就有多个，是比较脆弱的设计，应该将两种行为分离。 接口隔离原则（Interface Segregation Principle）接口隔离原则（Interface Segregation Principle）：用于恰当的划分角色和接口，具有两种含义：1、用户不应该依赖它不需要的接口；2、类间的依赖关系应该建立在最小的的接口上。 将这两个定义概括为一句话：建立单一接口，代替庞大臃肿的接口。通俗来说就是：接口尽量细化，同时保证接口中的方法尽量的少。一个接口中包含太多的行为时，会导致它们与客户端的不正常依赖关系，要做的就是分离接口，从而实现解耦。 回到上述的单一职责原则，要求行为分离接口接口细化，感觉有些相同。但实际上，单一职责原则要求类与接口的职责单一，注重的是职责，没有要求接口尽量的少。 在接口隔离原则中，要求尽量使用多个专门的接口。专门的接口也就是提供给多个模块的接口。提供给几个模块就应该有几个接口，而不是建立一个臃肿庞大的接口，所有的模块都可以访问。 但是接口的设计是有限度的。接口的设计粒度越小系统越灵活，这是事实，但是接口太多这也就使得结构复杂，维护难度大。因此实际中，怎样把握就靠开发的经验和常识了 迪米特法则（最少知道原则）（Demeter Principle）Law of Demeter（最小知识原则）：一个对象应该对其他对象有最少的了解。通俗来说就是，一个类对自己需要耦合或者调用的类知道的最少，你类内部怎么复杂，我不管，那是你的事，我只知道你有那么多公用的方法，我能调用。一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 迪米特原则不希望类与类之间建立直接的接触。如果真的需要有联系，那么就通过它们的友元类来传达。举例来说：你需要买房子了，现在存在三座合适的楼盘A，B，C，但是你不必直接去楼盘买楼，而是在售楼处去了解情况。这样就减少了你（购房者）与楼盘两个类之间耦合。 但是应用迪米特原则很可能会造成一个后果：系统会存在大量的中介类，这些类（如上面的售楼处类）之所以存在是为了传递类之间的相互调用关系，这就一定会程度上增加了系统的复杂度。 迪米特原则核心观念就是：类间解耦，弱耦合。 合成复用原则（Composite Reuse Principle）合成/聚合复用原则（Composite/Aggregate Reuse Principle，CARP）经常又叫做合成复用原则。合成/聚合复用原则就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分；新的对象通过向这些对象的委派达到复用已有功能的目的。它的设计原则是：要尽量使用合成/聚合，尽量不要使用继承。 设计模式的分类设计模式可以分为：创建型模式、结构型模式、行为型模式创建型模式作用：主要用于创建对象，为类实例化对象提供指南 结构型模式作用：主要用于处理类和对象的组合，对类如何设计以形成更大的结构提供指南 行为型模式作用：主要用于描述类或对象的交互以及职责的交互，对类之间交互以及分配责任提供指南 参考资料二十三种设计模式-六大原则一句话理解23种设计模式Java设计模式 七大原则（七） 组合/聚合复用原则（Composite/Aggregate Reuse Principle CARP）","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://brucy.cn/tags/设计模式/"}],"keywords":[]},{"title":"Mybatis","slug":"Mybatis","date":"2019-11-03T13:42:11.000Z","updated":"2019-11-04T13:35:30.737Z","comments":true,"path":"2019/11/03/Mybatis/","link":"","permalink":"http://brucy.cn/2019/11/03/Mybatis/","excerpt":"","text":"What is MyBatis? MyBatis is a first class persistence framework with support for custom SQL, stored procedures and advanced mappings. MyBatis eliminates almost all of the JDBC code and manual setting of parameters and retrieval of results. MyBatis can use simple XML or Annotations for configuration and map primitives, Map interfaces and Java POJOs (Plain Old Java Objects) to database records. MyBatis是一个一流的持久性框架，支持自定义SQL、存储过程和高级映射。MyBatis消除了几乎所有的JDBC代码和手动设置参数和检索结果。MyBatis可以使用简单的XML或注释进行配置，并将原语、映射接口和Java pojo(普通的旧Java对象)映射到数据库记录。 Configuration MyBatis Configuration 包含对MyBatis行为有显著影响的设置和属性。 文档的层级结构如下： configuration properties settings typeAliases typeHandlers objectFactory plugins environments environment transactionManager dataSource databaseIdProvider mappers properties 这些是可外部化的、可替换的属性，可以在典型的Java属性文件实例中配置，也可以通过properties元素的子元素传递。例如： &lt;properties resource=&quot;org/mybatis/example/config.properties&quot;&gt; &lt;property name=&quot;username&quot; value=&quot;dev_user&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;F2Fa3!33TYyg&quot;/&gt; &lt;/properties&gt;然后可以在整个配置文件中使用这些属性来替换需要动态配置的值。例如： &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;${driver}&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;${url}&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;${username}&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;${password}&quot;/&gt; &lt;/dataSource&gt;本例中的用户名和密码将被properties元素中设置的值替换。driver和url将被替换为在 config.properties 文件中设置的值。这为配置提供了许多选项。 Properties 也可以传递给SqlSessionFactoryBuilder.build()方法，例如： SqlSessionFactory factory = sqlSessionFactoryBuilder.build(reader, props); // ... or ... SqlSessionFactory factory = new SqlSessionFactoryBuilder.build(reader, environment, props);如果一个属性存在于这些位置中的一个以上，MyBatis将按以下顺序加载它们： 首先读取 Properties 中指定的 properties 元素, 第二读取 Properties 从 classpath 加载的资源或url属性的 properties 元素,并覆盖任何已经指定的重复属性, 最后读取作为方法参数传递的属性,并覆盖任何从 properties body 和 resource/url属性加载的 重复属性。 因此，优先级最高的属性是那些作为方法参数传入的属性，然后是resource/url属性，最后是properties元素主体中指定的属性。 在 MyBatis 3.4.2 之后，你可以在占位符中指定一个默认值，如下: &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;!-- ... --&gt; &lt;property name=&quot;username&quot; value=&quot;${username:ut_user}&quot;/&gt; &lt;!-- 如果“username”属性不存在，用户名将变为“ut_user” --&gt; &lt;/dataSource&gt;此功能在默认情况下是禁用的。如果你在占位符中指定了一个默认值，你应该通过添加一个特殊的属性来启用这个特性，如下所示: &lt;properties resource=&quot;org/mybatis/example/config.properties&quot;&gt; &lt;!-- ... --&gt; &lt;property name=&quot;org.apache.ibatis.parsing.PropertyParser.enable-default-value&quot; value=&quot;true&quot;/&gt; &lt;!-- 启用这个特性 --&gt; &lt;/properties&gt;注意，属性键中的“:”字符(例如db:username)和SQL语句中的三元运算符(例如${tableName != null ? tableName : ‘global_constants’})将会与默认属性产生冲突。 如果使用其中之一并希望使用默认属性值，则必须通过添加此特殊属性来更改默认值分隔符。 &lt;properties resource=&quot;org/mybatis/example/config.properties&quot;&gt; &lt;!-- ... --&gt; &lt;property name=&quot;org.apache.ibatis.parsing.PropertyParser.default-value-separator&quot; value=&quot;?:&quot;/&gt; &lt;!-- 更改分隔符的默认值separator --&gt; &lt;/properties&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;!-- ... --&gt; &lt;property name=&quot;username&quot; value=&quot;${db:username?:ut_user}&quot;/&gt; &lt;/dataSource&gt; settings Setting全局配置，它们修改了MyBatis在运行时的行为方式。下表描述了设置、它们的含义和默认值。 Setting 描述 可选项 默认值 cacheEnabled 配置全局缓存 true / false true lazyLoadingEnabled 延迟加载。对于特定关系，可以使用fetchType属性替换此值。 true 、 false false 设置元素完全配置的一个例子如下: &lt;settings&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt; &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot;/&gt; &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;false&quot;/&gt; &lt;setting name=&quot;autoMappingBehavior&quot; value=&quot;PARTIAL&quot;/&gt; &lt;setting name=&quot;autoMappingUnknownColumnBehavior&quot; value=&quot;WARNING&quot;/&gt; &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;SIMPLE&quot;/&gt; &lt;setting name=&quot;defaultStatementTimeout&quot; value=&quot;25&quot;/&gt; &lt;setting name=&quot;defaultFetchSize&quot; value=&quot;100&quot;/&gt; &lt;setting name=&quot;safeRowBoundsEnabled&quot; value=&quot;false&quot;/&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;false&quot;/&gt; &lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt; &lt;setting name=&quot;jdbcTypeForNull&quot; value=&quot;OTHER&quot;/&gt; &lt;setting name=&quot;lazyLoadTriggerMethods&quot; value=&quot;equals,clone,hashCode,toString&quot;/&gt; &lt;/settings&gt; typeAliases 类型别名是Java类型的短名称。它只与XML配置相关，它的存在只是为了减少完全限定类名的冗余类型化。 例如: &lt;typeAliases&gt; &lt;typeAlias alias=&quot;Author&quot; type=&quot;domain.blog.Author&quot;/&gt; &lt;typeAlias alias=&quot;Blog&quot; type=&quot;domain.blog.Blog&quot;/&gt; &lt;typeAlias alias=&quot;Comment&quot; type=&quot;domain.blog.Comment&quot;/&gt; &lt;typeAlias alias=&quot;Post&quot; type=&quot;domain.blog.Post&quot;/&gt; &lt;typeAlias alias=&quot;Section&quot; type=&quot;domain.blog.Section&quot;/&gt; &lt;typeAlias alias=&quot;Tag&quot; type=&quot;domain.blog.Tag&quot;/&gt; &lt;/typeAliases&gt;别名可以全局使用。您还可以指定一个包，MyBatis将在其中搜索bean。例如: &lt;typeAliases&gt; &lt;package name=&quot;domain.blog&quot;/&gt; &lt;/typeAliases&gt;在domain.blog中找到的任何bean，如果没有找到任何注解，将使用bean的非大写限定类名注册为别名。这是domain.blog。domain.blog.Author 将被注册为author。如果找到@Alias注释，它的值会用作别名。请看下面的例子: @Alias(&quot;author&quot;) public class Author { ... }常见Java类型有许多内置的类型别名。它们都不区分大小写，请注意由于重载名称而对原语的特殊处理。 Alias Mapped Type Alias Mapped Type Alias Mapped Type Alias Mapped Type _byte byte _long long _short short _int int _integer int _double double _float float _boolean boolean string String byte Byte long Long short Short int Integer integer Integer double Double float Float boolean Boolean date Date decimal BigDecimal bigdecimal BigDecimal object Object map Map hashmap HashMap list List arraylist ArrayList collection Collection iterator Iterator — typeHandlers 每当MyBatis在PreparedStatement上设置一个参数或从ResultSet检索一个值时，都会使用一个类型处理器以适合Java类型的方式检索该值。Java类型与数据库类型之间的映射，即JavaType与jdbcType之间的映射。下表描述了默认的TypeHandlers。 注意:从3.4.5版开始，MyBatis默认支持JSR-310(日期和时间API)。 Type Handler Java Types JDBC Types BooleanTypeHandler java.lang.Boolean, boolean Any compatible BOOLEAN ByteTypeHandler java.lang.Byte, byte Any compatible NUMERIC or BYTE ShortTypeHandler java.lang.Short, short Any compatible NUMERIC or SMALLINT IntegerTypeHandler java.lang.Integer, int Any compatible NUMERIC or INTEGER LongTypeHandler java.lang.Long, long Any compatible NUMERIC or BIGINT FloatTypeHandler java.lang.Float, float Any compatible NUMERIC or FLOAT DoubleTypeHandler java.lang.Double, double Any compatible NUMERIC or DOUBLE BigDecimalTypeHandler java.math.BigDecimal Any compatible NUMERIC or DECIMAL StringTypeHandler java.lang.String CHAR, VARCHAR ClobReaderTypeHandler java.io.Reader - ClobTypeHandler java.lang.String CLOB, LONGVARCHAR NStringTypeHandler java.lang.String NVARCHAR, NCHAR NClobTypeHandler java.lang.String NCLOB BlobInputStreamTypeHandler java.io.InputStream - ByteArrayTypeHandler byte[] Any compatible byte stream type BlobTypeHandler byte[] BLOB, LONGVARBINARY DateTypeHandler java.util.Date TIMESTAMP DateOnlyTypeHandler java.util.Date DATE TimeOnlyTypeHandler java.util.Date mestamp SqlDateTypeHandler java.sql.Date DATE SqlTimeTypeHandler java.sql.Time TIME ObjectTypeHandler Any OTHER, or unspecified EnumTypeHandler Enumeration Type VARCHAR any string compatible type, as the code is stored (not index). EnumOrdinalTypeHandler Enumeration Type Any compatible NUMERIC or DOUBLE, as the position is stored (not the code itself). SqlxmlTypeHandler java.lang.String SQLXML InstantTypeHandler java.time.Instant TIMESTAMP LocalDateTimeTypeHandler java.time.LocalDateTime TIMESTAMP LocalDateTypeHandler java.time.LocalDate DATE LocalTimeTypeHandler java.time.LocalTime TIME OffsetDateTimeTypeHandler java.time.OffsetDateTime TIMESTAMP OffsetTimeTypeHandler java.time.OffsetTime TIME ZonedDateTimeTypeHandler java.time.ZonedDateTime TIMESTAMP YearTypeHandler java.time.Year INTEGER MonthTypeHandler java.time.Month INTEGER YearMonthTypeHandler java.time.YearMonth VARCHAR or LONGVARCHAR JapaneseDateTypeHandler java.time.chrono.JapaneseDate DATE 您可以覆盖TypeHandler，也可以创建自己的TypeHandler来处理不受支持的或非标准的类型。为此，请实现接口org.apache.ibatis.type.TypeHandler或扩展类org.apache.ibatis.type.BaseTypeHandler并可选地将其映射到JDBC类型。例如: // ExampleTypeHandler.java @MappedJdbcTypes(JdbcType.VARCHAR) public class ExampleTypeHandler extends BaseTypeHandler&lt;String&gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException { ps.setString(i, parameter); } @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException { return rs.getString(columnName); } @Override public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException { return rs.getString(columnIndex); } @Override public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { return cs.getString(columnIndex); } }&lt;!-- mybatis-config.xml --&gt; &lt;typeHandlers&gt; &lt;typeHandler handler=&quot;org.mybatis.example.ExampleTypeHandler&quot;/&gt; &lt;/typeHandlers&gt;使用这样的TypeHandler将覆盖现有的用于Java字符串属性、VARCHAR参数和查询结果的TypeHandler。请注意，MyBatis不内省数据库元数据来确定类型，因此必须在参数和结果映射中指定VARCHAR字段，以便在正确的类型处理程序中进行hook。这是因为在执行语句之前MyBatis并不知道数据类型。Using such a TypeHandler would override the existing type handler for Java String properties and VARCHAR parameters and results. Note that MyBatis does not introspect upon the database metadata to determine the type, so you must specify that it’s a VARCHAR field in the parameter and result mappings to hook in the correct type handler. This is due to the fact that MyBatis is unaware of the data type until the statement is executed. MyBatis将通过自省它的泛型类型来知道你想用这个类型处理器处理的Java类型，但是你可以通过两种方式来覆盖这个行为:MyBatis will know the Java type that you want to handle with this TypeHandler by introspecting its generic type, but you can override this behavior by two means: 向typeHandler元素添加javaType属性(例如:javaType=”String”) 向TypeHandler类添加@MappedTypes注解，以指定与其关联的Java类型列表。如果已经指定了javaType属性，则该注释将被忽略。 关联的JDBC类型可以通过两种方式指定: 向typeHandler元素添加jdbcType属性（例如：jdbcType =“ VARCHAR”）。 将@MappedJdbcTypes注解添加到TypeHandler类中，以指定与其关联的JDBC类型列表。如果已经指定了jdbcType属性，则将忽略此注解 在决定要在ResultMap中使用哪种TypeHandler时，Java类型是已知的（从结果类型中），但是JDBC类型是未知的。因此，MyBatis使用组合 javaType = [TheJavaType]，jdbcType = null来选择TypeHandler。这意味着，使用@MappedJdbcTypes注解会限制TypeHandler的范围，除非明确设置，否则无法在ResultMap中使用。为了使可用于在使用一个类型处理器的ResultMap，设置includeNullJdbcType = true 的@MappedJdbcTypes注释。由于MyBatis的3.4.0但是，如果单 类型处理器被注册为处理Java类型，它会被默认使用的ResultMap S使用该Java类型（即，即使没有includeNullJdbcType = TRUE）。When deciding which TypeHandler to use in a ResultMap, the Java type is known (from the result type), but the JDBC type is unknown. MyBatis therefore uses the combination javaType=[TheJavaType], jdbcType=null to choose a TypeHandler. This means that using a @MappedJdbcTypes annotation restricts the scope of a TypeHandler and makes it unavailable for use in ResultMaps unless explicity set. To make a TypeHandler available for use in a ResultMap, set includeNullJdbcType=true on the @MappedJdbcTypes annotation.Since Mybatis 3.4.0 however, if a single TypeHandler is registered to handle a Java type, it will be used by default in ResultMaps using this Java type (i.e. even without includeNullJdbcType=true). And finally you can let MyBatis search for your TypeHandlers: &lt;!-- mybatis-config.xml --&gt; &lt;typeHandlers&gt; &lt;package name=&quot;org.mybatis.example&quot;/&gt; &lt;/typeHandlers&gt;Note that when using the autodiscovery feature JDBC types can only be specified with annotations. You can create a generic TypeHandler that is able to handle more than one class. For that purpose add a constructor that receives the class as a parameter and MyBatis will pass the actual class when constructing the TypeHandler. //GenericTypeHandler.java public class GenericTypeHandler&lt;E extends MyObject&gt; extends BaseTypeHandler&lt;E&gt; { private Class&lt;E&gt; type; public GenericTypeHandler(Class&lt;E&gt; type) { if (type == null) throw new IllegalArgumentException(&quot;Type argument cannot be null&quot;); this.type = type; } ...EnumTypeHandler和EnumOrdinalTypeHandler是通用TypeHandler。 Handling Enums如果要映射Enum，则需要使用 EnumTypeHandler或EnumOrdinalTypeHandler。 注意EnumTypeHandler的特殊之处在于，它与其他处理程序不同，它不仅处理一个特定的类，而且还处理任何扩展Enum的类。Note EnumTypeHandler is special in the sense that unlike other handlers, it does not handle just one specific class, but any class that extends EnumHowever, we may not want to store names. Our DBA may insist on an integer code instead. That’s just as easy: add EnumOrdinalTypeHandler to the typeHandlers in your config file, and now each RoundingMode will be mapped to an integer using its ordinal value. &lt;!-- mybatis-config.xml --&gt; &lt;typeHandlers&gt; &lt;typeHandler handler=&quot;org.apache.ibatis.type.EnumOrdinalTypeHandler&quot; javaType=&quot;java.math.RoundingMode&quot;/&gt; &lt;/typeHandlers&gt;But what if you want to map the same Enum to a string in one place and to integer in another? The auto-mapper will automatically use EnumOrdinalTypeHandler, so if we want to go back to using plain old ordinary EnumTypeHandler, we have to tell it, by explicitly setting the type handler to use for those SQL statements. (Mapper files aren’t covered until the next section, so if this is your first time reading through the documentation, you may want to skip this for now and come back to it later.) &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace=&quot;org.apache.ibatis.submitted.rounding.Mapper&quot;&gt; &lt;resultMap type=&quot;org.apache.ibatis.submitted.rounding.User&quot; id=&quot;usermap&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;name&quot; property=&quot;name&quot;/&gt; &lt;result column=&quot;funkyNumber&quot; property=&quot;funkyNumber&quot;/&gt; &lt;result column=&quot;roundingMode&quot; property=&quot;roundingMode&quot;/&gt; &lt;/resultMap&gt; &lt;select id=&quot;getUser&quot; resultMap=&quot;usermap&quot;&gt; select * from users &lt;/select&gt; &lt;insert id=&quot;insert&quot;&gt; insert into users (id, name, funkyNumber, roundingMode) values ( #{id}, #{name}, #{funkyNumber}, #{roundingMode} ) &lt;/insert&gt; &lt;resultMap type=&quot;org.apache.ibatis.submitted.rounding.User&quot; id=&quot;usermap2&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;name&quot; property=&quot;name&quot;/&gt; &lt;result column=&quot;funkyNumber&quot; property=&quot;funkyNumber&quot;/&gt; &lt;result column=&quot;roundingMode&quot; property=&quot;roundingMode&quot; typeHandler=&quot;org.apache.ibatis.type.EnumTypeHandler&quot;/&gt; &lt;/resultMap&gt; &lt;select id=&quot;getUser2&quot; resultMap=&quot;usermap2&quot;&gt; select * from users2 &lt;/select&gt; &lt;insert id=&quot;insert2&quot;&gt; insert into users2 (id, name, funkyNumber, roundingMode) values ( #{id}, #{name}, #{funkyNumber}, #{roundingMode, typeHandler=org.apache.ibatis.type.EnumTypeHandler} ) &lt;/insert&gt; &lt;/mapper&gt;Note that this forces us to use a resultMap instead of a resultType in our select statements. objectFactoryMyBatis每次都会使用ObjectFactory实例来创建result对象实例。默认的 ObjectFactory 除了使用默认的构造函数实例化目标类外，如果存在参数映射，则使用参数化的构造函数实例化目标类。如果要覆盖ObjectFactory的默认行为，则可以创建自己的行为。例如： // ExampleObjectFactory.java public class ExampleObjectFactory extends DefaultObjectFactory { @Override public &lt;T&gt; T create(Class&lt;T&gt; type) { return super.create(type); } @Override public &lt;T&gt; T create(Class&lt;T&gt; type, List&lt;Class&lt;?&gt;&gt; constructorArgTypes, List&lt;Object&gt; constructorArgs) { return super.create(type, constructorArgTypes, constructorArgs); } @Override public void setProperties(Properties properties) { super.setProperties(properties); } @Override public &lt;T&gt; boolean isCollection(Class&lt;T&gt; type) { return Collection.class.isAssignableFrom(type); }}&lt;!-- mybatis-config.xml --&gt; &lt;objectFactory type=&quot;org.mybatis.example.ExampleObjectFactory&quot;&gt; &lt;property name=&quot;someProperty&quot; value=&quot;100&quot;/&gt; &lt;/objectFactory&gt;ObjectFactory接口非常简单。它包含两种创建方法，一种用于处理默认构造函数，另一种用于处理参数化构造函数。最后，可以使用setProperties方法配置ObjectFactory。在初始化ObjectFactory实例后，把在ObjectFactory的主体内定义的属性 传递给setProperties方法。 plugins MyBatis允许您在映射语句的执行过程中的某些点拦截调用。默认情况下，MyBatis允许插件拦截以下方法的调用： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) 如果尝试修改或覆盖给定方法的行为，则很可能会破坏MyBatis的核心。这些是底层的类和方法，因此请谨慎使用插件。，使用插件非常简单。只需实现Interceptor接口，并指定要拦截的标志即可。 // ExamplePlugin.java @Intercepts({@Signature( type= Executor.class, method = &quot;update&quot;, args = {MappedStatement.class,Object.class})}) public class ExamplePlugin implements Interceptor { private Properties properties = new Properties(); @Override public Object intercept(Invocation invocation) throws Throwable { // implement pre-processing if needed Object returnObject = invocation.proceed(); // implement post-processing if needed return returnObject; } @Override public void setProperties(Properties properties) { this.properties = properties; } }&lt;!-- mybatis-config.xml --&gt; &lt;plugins&gt; &lt;plugin interceptor=&quot;org.mybatis.example.ExamplePlugin&quot;&gt; &lt;property name=&quot;someProperty&quot; value=&quot;100&quot;/&gt; &lt;/plugin&gt; &lt;/plugins&gt;上面的插件将拦截Executor实例上对“ update”方法的所有调用。注意覆盖配置类除了使用插件修改MyBatis核心行为外，您还可以完全覆盖Configuration类。只需对其进行扩展并覆盖其中的任何方法，然后将其传递给SqlSessionFactoryBuilder.build（myConfig）方法的调用即可 。这可能会对MyBatis的行为产生严重影响，因此请谨慎使用。 environments MyBatis可以配置多个环境。这有助于您将SQL映射应用到多个数据库。例如，您的开发、测试和生产环境可能有不同的配置。或者，您可能有多个共享相同模式的生产数据库，您希望对这两个数据库使用相同的SQL映射。 虽然您可以配置多个环境，但是您只能为每个SqlSessionFactory实例选择一个。 因此，如果希望连接两个数据库，需要创建两个SqlSessionFactory实例。对于三个数据库，您需要三个实例。 每个数据库一个SqlSessionFactory实例来指定要构建的环境，只需将SqlSessionFactory实例作为一个可选参数传递给SqlSessionFactoryBuilder即可。接受环境的两个签名是: SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment); SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment, properties);如果省略环境，则加载默认环境，如下所示: SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader); SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, properties);environments 配置如下： &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;&gt; &lt;property name=&quot;...&quot; value=&quot;...&quot;/&gt; &lt;/transactionManager&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;${driver}&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;${url}&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;${username}&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;${password}&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;注意这里的关键部分: 默认环境 ID (e.g. default=”development”) environment 的 ID (e.g. id=”development”) TransactionManager(事务管理器)配置 (e.g. type=”JDBC”) DataSource 数据源配置 (e.g. type=”POOLED”) 您可以随意命名 environment ID ，只要确保默认与其中一个匹配即可。 transactionManager 在MyBatis中有两种TransactionManager类型(即type=”[JDBC|MANAGED]”) JDBC – 此配置只是直接使用JDBC提交和回滚功能。 MANAGED – 这种配置几乎什么都不做。它从不提交或回滚连接。它让容器管理事务的整个生命周期(例如：JEE Application Server context)。默认情况下，它会关闭连接。但是，有些容器不希望这样，因此，如果不希望关闭连接，请将“closeConnection”属性设置为false。 例如 : &lt;transactionManager type=&quot;MANAGED&quot;&gt; &lt;property name=&quot;closeConnection&quot; value=&quot;false&quot;/&gt; &lt;/transactionManager&gt;注意，如果您计划在Spring中使用MyBatis，那么不需要配置任何TransactionManager，因为Spring模块将设置自己的一个TransactionManager，覆盖以前设置的任何配置。 NOTE If you are planning to use MyBatis with Spring there is no need to configure any TransactionManager because the Spring module will set its own one overriding any previously set configuration. Neither of these TransactionManager types require any properties. However, they are both Type Aliases, so in other words, instead of using them, you could put your own fully qualified class name or Type Alias that refers to your own implementation of the TransactionFactory interface. public interface TransactionFactory { default void setProperties(Properties props) { // Since 3.5.2, change to default method // NOP } Transaction newTransaction(Connection conn); Transaction newTransaction(DataSource dataSource, TransactionIsolationLevel level, boolean autoCommit);}Any properties configured in the XML will be passed to the setProperties() method after instantiation. Your implementation would also need to create a Transaction implementation, which is also a very simple interface: public interface Transaction { Connection getConnection() throws SQLException; void commit() throws SQLException; void rollback() throws SQLException; void close() throws SQLException; Integer getTimeout() throws SQLException;}Using these two interfaces, you can completely customize how MyBatis deals with Transactions. dataSource The dataSource element configures the source of JDBC Connection objects using the standard JDBC DataSource interface. Most MyBatis applications will configure a dataSource as in the example. However, it’s not required. Realize though, that to facilitate Lazy Loading, this dataSource is required. There are three built-in dataSource types (i.e. type=”[UNPOOLED|POOLED|JNDI]”): UNPOOLED – This implementation of DataSource simply opens and closes a connection each time it is requested. While it’s a bit slower, this is a good choice for simple applications that do not require the performance of immediately available connections. Different databases are also different in this performance area, so for some it may be less important to pool and this configuration will be ideal. The UNPOOLED DataSource has the following properties to configure: driver – This is the fully qualified Java class of the JDBC driver (NOT of the DataSource class if your driver includes one).url – This is the JDBC URL for your database instance.username – The database username to log in with.password - The database password to log in with.defaultTransactionIsolationLevel – The default transaction isolation level for connections.defaultNetworkTimeout – The default network timeout value in milliseconds to wait for the database operation to complete. See the API documentation of java.sql.Connection#setNetworkTimeout() for details.Optionally, you can pass properties to the database driver as well. To do this, prefix the properties with driver., for example: driver.encoding=UTF8This will pass the property encoding, with the value UTF8, to your database driver via the DriverManager.getConnection(url, driverProperties) method. POOLED – This implementation of DataSource pools JDBC Connection objects to avoid the initial connection and authentication time required to create a new Connection instance. This is a popular approach for concurrent web applications to achieve the fastest response. In addition to the (UNPOOLED) properties above, there are many more properties that can be used to configure the POOLED datasource: poolMaximumActiveConnections – This is the number of active (i.e. in use) connections that can exist at any given time. Default: 10poolMaximumIdleConnections – The number of idle connections that can exist at any given time.poolMaximumCheckoutTime – This is the amount of time that a Connection can be “checked out” of the pool before it will be forcefully returned. Default: 20000ms (i.e. 20 seconds)poolTimeToWait – This is a low level setting that gives the pool a chance to print a log status and re-attempt the acquisition of a connection in the case that it’s taking unusually long (to avoid failing silently forever if the pool is misconfigured). Default: 20000ms (i.e. 20 seconds)poolMaximumLocalBadConnectionTolerance – This is a low level setting about tolerance of bad connections got for any thread. If a thread got a bad connection, it may still have another chance to re-attempt to get another connection which is valid. But the retrying times should not more than the sum of poolMaximumIdleConnections and poolMaximumLocalBadConnectionTolerance. Default: 3 (Since: 3.4.5)poolPingQuery – The Ping Query is sent to the database to validate that a connection is in good working order and is ready to accept requests. The default is “NO PING QUERY SET”, which will cause most database drivers to fail with a decent error message.poolPingEnabled – This enables or disables the ping query. If enabled, you must also set the poolPingQuery property with a valid SQL statement (preferably a very fast one). Default: false.poolPingConnectionsNotUsedFor – This configures how often the poolPingQuery will be used. This can be set to match the typical timeout for a database connection, to avoid unnecessary pings. Default: 0 (i.e. all connections are pinged every time – but only if poolPingEnabled is true of course).JNDI – This implementation of DataSource is intended for use with containers such as EJB or Application Servers that may configure the DataSource centrally or externally and place a reference to it in a JNDI context. This DataSource configuration only requires two properties: initial_context – This property is used for the Context lookup from the InitialContext (i.e. initialContext.lookup(initial_context)). This property is optional, and if omitted, then the data_source property will be looked up against the InitialContext directly.data_source – This is the context path where the reference to the instance of the DataSource can be found. It will be looked up against the context returned by the initial_context lookup, or against the InitialContext directly if no initial_context is supplied.Similar to the other DataSource configurations, it’s possible to send properties directly to the InitialContext by prefixing those properties with env., for example: env.encoding=UTF8This would send the property encoding with the value of UTF8 to the constructor of the InitialContext upon instantiation. You can plug any 3rd party DataSource by implementing the interface org.apache.ibatis.datasource.DataSourceFactory: public interface DataSourceFactory { void setProperties(Properties props); DataSource getDataSource();}org.apache.ibatis.datasource.unpooled.UnpooledDataSourceFactory can be used as super class to build new datasource adapters. For example this is the code needed to plug C3P0: import org.apache.ibatis.datasource.unpooled.UnpooledDataSourceFactory;import com.mchange.v2.c3p0.ComboPooledDataSource; public class C3P0DataSourceFactory extends UnpooledDataSourceFactory { public C3P0DataSourceFactory() { this.dataSource = new ComboPooledDataSource(); }}To set it up, add a property for each setter method you want MyBatis to call. Follows below a sample configuration which connects to a PostgreSQL database: databaseIdProvider MyBatis is able to execute different statements depending on your database vendor. The multi-db vendor support is based on the mapped statements databaseId attribute. MyBatis will load all statements with no databaseId attribute or with a databaseId that matches the current one. In case the same statement is found with and without the databaseId the latter will be discarded. To enable the multi vendor support add a databaseIdProvider to mybatis-config.xml file as follows: The DB_VENDOR implementation databaseIdProvider sets as databaseId the String returned by DatabaseMetaData#getDatabaseProductName(). Given that usually that string is too long and that different versions of the same product may return different values, you may want to convert it to a shorter one by adding properties like follows: When properties are provided, the DB_VENDOR databaseIdProvider will search the property value corresponding to the first key found in the returned database product name or \"null\" if there is not a matching property. In this case, if getDatabaseProductName() returns \"Oracle (DataDirect)\" the databaseId will be set to \"oracle\". You can build your own DatabaseIdProvider by implementing the interface org.apache.ibatis.mapping.DatabaseIdProvider and registering it in mybatis-config.xml: public interface DatabaseIdProvider { default void setProperties(Properties p) { // Since 3.5.2, changed to default method // NOP } String getDatabaseId(DataSource dataSource) throws SQLException; }mappersNow that the behavior of MyBatis is configured with the above configuration elements, we’re ready to define our mapped SQL statements. But first, we need to tell MyBatis where to find them. Java doesn’t really provide any good means of auto-discovery in this regard, so the best way to do it is to simply tell MyBatis where to find the mapping files. You can use classpath relative resource references, fully qualified url references (including file:/// URLs), class names or package names. For example: &lt;!-- Using classpath relative resources --&gt; &lt;mappers&gt; &lt;mapper resource=&quot;org/mybatis/builder/AuthorMapper.xml&quot;/&gt; &lt;mapper resource=&quot;org/mybatis/builder/BlogMapper.xml&quot;/&gt; &lt;mapper resource=&quot;org/mybatis/builder/PostMapper.xml&quot;/&gt; &lt;/mappers&gt;&lt;!-- Using url fully qualified paths --&gt; &lt;mappers&gt; &lt;mapper url=&quot;file:///var/mappers/AuthorMapper.xml&quot;/&gt; &lt;mapper url=&quot;file:///var/mappers/BlogMapper.xml&quot;/&gt; &lt;mapper url=&quot;file:///var/mappers/PostMapper.xml&quot;/&gt; &lt;/mappers&gt; &lt;!-- Using mapper interface classes --&gt; &lt;mappers&gt; &lt;mapper class=&quot;org.mybatis.builder.AuthorMapper&quot;/&gt; &lt;mapper class=&quot;org.mybatis.builder.BlogMapper&quot;/&gt; &lt;mapper class=&quot;org.mybatis.builder.PostMapper&quot;/&gt; &lt;/mappers&gt;&lt;!-- Register all interfaces in a package as mappers --&gt; &lt;mappers&gt; &lt;package name=&quot;org.mybatis.builder&quot;/&gt; &lt;/mappers&gt;These statement simply tell MyBatis where to go from here. The rest of the details are in each of the SQL Mapping files, and that’s exactly what the next section will discuss.","categories":[],"tags":[],"keywords":[]},{"title":"Object类","slug":"Object类","date":"2019-10-31T12:08:51.000Z","updated":"2019-11-06T06:17:15.815Z","comments":true,"path":"2019/10/31/Object类/","link":"","permalink":"http://brucy.cn/2019/10/31/Object类/","excerpt":"","text":"Objectobject的概述： A、 object是所有的类父类 B、 object中的所有方法，子类都能使用（接口不是object的子类）Object 类中常用方法 A、equals() 底层调用其实就是== 方法 == 方法： 基本数据类： 比较的是内容(值) 引用数据类型：比较的是内存地址值 String 的equals比较的是内容 B、String toString() 问题：为什么要重写toString()方法 答：打印时默认会调用toString()方法 因为toString()方法来源于object中，object中getClass.getName()+&quot;@&quot; +Integer.toHexString(hasCode() ) ---&gt;打印就是内存地址值 很多时候，我们不想看见内存地址值，想看到的是子类的特有属性值，这时就需要重写toString()方法String 在String 中认为都是对象，String str = &quot;...&quot;; 所以str 是对象，&quot;&quot;也是对象 String 是一个常量，其本质就是private final 修饰的字符数组 String的构造方法: new String(byte [] bytes, int offset,int length); offset: 数据解锁起始位置 length:需要解锁的位数 面试题object类有哪些方法1. clone方法 protected方法，实现对象的浅拷贝，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportException异常 浅复制：将一个对象复制后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。 深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。 简单来说，就是深复制进行了完全彻底的复制，而浅复制不彻底。 2. getClass方法 final方法，获得运行类 3. toString方法 该方法用得比较多，一般子类都有覆盖。 4. finalize方法 该方法用于释放资源。因为无法确定该方法什么时候被调用，很少使用。 5. equals方法 该方法是非常重要的一个方法。一般equals和==是不一样的，但是在Object中两者是一样的。子类一般都要重写这个方法。 6. hashCode方法 该方法用于哈希查找，可以减少在查找中使用equals的次数， 重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。 一般满足 obj1.equals(obj2) = true。可以推出obj1.hashCode() = obj2.hashCode()，但是hashCode相等不一定就满足equals。 不过为了提高效率，应该尽量使上面两个条件接近等价。 如果不重写hashcode(),在HashSet中添加两个equals的对象，会将两个对象都加入进去。 7. wait方法 导致当前线程等待，直到它被唤醒 唤醒当前线程的方法： 1. 其他线程调用了该对象的 notify 方法 2. 其他线程调用了该对象的notifyAll方法 3. 其他线程调用了interrupt中断该线程 4. 设置的等待时间到了 8. notify方法 该方法唤醒在该对象上等待的某个线程。 9. notifyAll方法 该方法唤醒在该对象上等待的所有线程。final1. 修饰类 ： 不能被继承 2. 修饰方法 ： 不能被重写 3. 修饰变量 ： 基本数据类型： 值不能改变 4. 引用数据类型： 地址值不能改变重写和重载重写：子类中出现和父类方法声明一模一样的方法,重写 重载：本类中出现方法名相同，但参数列表不同，注意：与返回值类型无关封装封装好处： A、提高了代码的复用性 B、提高了代码的安全性 C、隐藏了对象实现的细节，仅仅对外提供方法继承A、提高了代码的复用性 B、提高了代码的可维护性 C、使类和类之间耦合起来了，这是多态的前提 开发的原则：高内聚，低耦合 内聚：完成一个功能的能力 耦合：类和类之间的关系 继承的注意事项： 1、 子类继承父类，只能继承父类中非private修饰的成员变量和方法 2、 简单说：子类有，父类有，找子类，子类没有，父类有，找父类 参考资料： Object类有哪些方法？各有什么作用？","categories":[],"tags":[],"keywords":[]},{"title":"ClassLoader","slug":"ClassLoader","date":"2019-10-28T02:51:51.000Z","updated":"2019-10-29T13:20:55.102Z","comments":true,"path":"2019/10/28/ClassLoader/","link":"","permalink":"http://brucy.cn/2019/10/28/ClassLoader/","excerpt":"","text":"一、ClassLoader 定义ClassLoader的作用就是根据一个指定的类的全限定名,找到对应的Class字节码文件,然后加载它转化成一个java.lang.Class类的一个实例。 所有Class都是由classloader进行加载的，ClassLoader负责通过将Class文件里的二进制数据流装载进系统，然后交给java虚拟机进行连接、初始化等操作。 JVM 运行实例中会存在多个 ClassLoader，不同的 ClassLoader 会从不同的地方加载字节码文件。它可以从不同的文件目录加载，也可以从不同的 jar 文件中加载，也可以从网络上不同的静态文件服务器来下载字节码再加载。 二、分类BootStrap ClassLoaderBootStrap ClassLoader 是Java类加载层次中最顶层的类加载器，负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar 和 java.lang 包下的文件等。由C++ 编写，不能被java程序直接调用，是虚拟机的一部分。 Extendsion ClassLaoder加载扩展库 javax.* ; 主要加载\\bin\\ext 下的类库。由java编写，可以把自己写的包放进去，也就是说开发者可以直接使用这个类加载器。 App ClassLoader加载用户类路径（CLASSPATH）下的类库，用户自己的代码以及第三方jar包通常由APP ClassLoader 来加载。一般情况下这就是系统默认的类加载器。 自定义 ClassLoader用户可自定义 ClassLoader 只要传入defineClass的二进制流是合法的，就可以通过不同形式去加载。如访问远程网络获取二进制流。通过重写findClass方法可以对加密过的class进行解密、实现字节码增强技术、ASM 等。 三、双亲委派机制3.1、类加载器的层次首先明确一个类加载器的层次结构，ClassLoader并没有继承其他类，但有一个 parent属性记录了当前类加载器的父类加载器自定义 ClassLoader 的父类加载器是 App ClassLoaderApp ClassLoader 的父类加载器是 Extendsion ClassLaoderExtendsion ClassLaoder 没有父类加载器，它的 parent 是 null public abstract class ClassLoader { private static native void registerNatives(); static { registerNatives(); } // 委托的父类加载器 // 注意:VM硬编码了这个字段的偏移量，因此所有的新字段都必须添加“after” private final ClassLoader parent; // 类加载器的名字 private final String name;3.2、双亲委派机制当需要加载某个类时，类加载器不会第一时间进行加载，而是查看父类是否加载过该类。如果父类已经加载过这个类，就直接使用该类不再加载，如果父类不曾加载过该类，就检查父类的父类是否加载过。当检查到 BootStrap ClassLoader 都没有加载过该类的话，由 BootStrap ClassLoader尝试加载该类，如果加载失败就交给 BootStrap ClassLoader 的子类尝试加载。若任加载失败，就交给子类的子类进行加载以此类推。 ClassLoader 中的 loadClass 方法 protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { // 为了避免多个线程同时进行加载造成重复加载一个类，所以在这里加一个同步锁 synchronized (getClassLoadingLock(name)) { // 首先，检查类是否已经加载 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { // 检查当前类加载器的 parent 是否为空 if (parent != null) { // parent 不为空让 parent调用此方法 c = parent.loadClass(name, false); } else { // parent 为空就让 BootStrap ClassLoader去尝试加载 c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // 如果没有找到类，则抛出ClassNotFoundException // 异常来自非空父类加载器 } if (c == null) { // 如果仍未找到，则按顺序调用findClass，去查找类 long t1 = System.nanoTime(); c = findClass(name); // 这是定义类加载器，并记录数据 PerfCounter.getParentDelegationTime().addTime(t1 - t0); PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } }为了避免重复加载，当父亲已经加载了该类的时候，就没有必要 ClassLoader再加载一次。考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时就被引导类加载器（Bootstrcp ClassLoader）加载，所以用户自定义的ClassLoader永远也无法加载一个自己写的String，除非你改变JDK中ClassLoader搜索类的默认算法。 ClassLoader.loadClass 方法与 Class.forName 方法比较 : 相同：都可以显示地加载某个类。不同：通过 forName 方法加载的类已经完成类的初始化，而通过 loadClass 方法加载的类没有进行初始化。 使用loadClass方法加载类可以等到需要使用某个类的时候才进行初始化，达到延时加载的效果。 四、自定义一个类加载器提前在桌面建一个 Wali.java 文件，并编译出 Wali.class 文件待用。 public class Wali{ static{ System.out.println(&quot;Wali&quot;); } }package test; import java.io.ByteArrayOutputStream; import java.io.File; import java.io.FileInputStream; import java.io.IOException; import java.io.InputStream; public class myClassLoader extends ClassLoader { private String path; private String className; public myClassLoader(String path, String className) { this.path = path; this.className = className; } // 寻找类文件 @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { byte[] b = loadClassData(name); return defineClass(name, b, 0, b.length); } // 加载类文件 public byte[] loadClassData(String name) { name = path + name + &quot;.class&quot;; InputStream in = null; ByteArrayOutputStream out = null; try { in = new FileInputStream(new File(name)); out = new ByteArrayOutputStream(); int i = 0; while((i = in.read()) != -1) { out.write(i); } }catch (Exception e) { e.printStackTrace(); }finally { try { out.close(); in.close(); } catch (IOException e) { e.printStackTrace(); } } return out.toByteArray(); } } 测试是否可以通过自定义类加载器加载 Wali 这个类 package test; public class ClassLoaderChecker { @SuppressWarnings(&quot;all&quot;) public static void main(String[] args) throws ClassNotFoundException, InstantiationException, IllegalAccessException { myClassLoader myClass = new myClassLoader(&quot;C:\\\\Users\\\\Administrator\\\\Desktop\\\\&quot;, &quot;Wali.class&quot;); Class c = myClass.loadClass(&quot;Wali&quot;); System.out.println(c.getClassLoader()); c.newInstance(); } }结果：成功加载到了该类，控制台输出： Wali","categories":[],"tags":[],"keywords":[]},{"title":"java-反射","slug":"java-反射","date":"2019-10-27T09:30:54.000Z","updated":"2019-10-27T12:59:04.594Z","comments":true,"path":"2019/10/27/java-反射/","link":"","permalink":"http://brucy.cn/2019/10/27/java-反射/","excerpt":"","text":"一、定义JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。 二、与反射相关的几个类 Field类：提供有关类或接口的属性的信息，以及对它的动态访问权限。反射的字段可能是一个类（静态）属性或实例属性，简单的理解可以把它看成一个封装反射类的属性的类。 Constructor类：提供关于类的单个构造方法的信息以及对它的访问权限。这个类和Field类不同，Field类封装了反射类的属性，而Constructor类则封装了反射类的构造方法。 Method类：提供关于类或接口上单独某个方法的信息。所反映的方法可能是类方法或实例方法（包括抽象方法）。 这个类不难理解，它是用来封装反射类方法的一个类。 Class类：Class 类的实例用来表示正在运行的 Java 应用程序中的类和接口。 Object类：每个类都使用 Object 作为超类。所有对象（包括数组）都实现这个类的方法。 三、运用反射机制3.1、反射中常用APIClassClass 类的实例用来表示正在运行的 Java 应用程序中的类和接口。 方法 用途 asSubclass(Class&lt; T &gt; clazz) 把传递的类的对象转换成代表其子类的对象 Cast 把对象转换成代表类或是接口的对象 getClassLoader() 获得类的加载器 getClasses() 返回一个数组，数组中包含该类中所有公共类和接口类的对象 getDeclaredClasses() 返回一个数组，数组中包含该类中所有类和接口类的对象 forName(String className) 根据类名返回类的对象 getName() 获得类的完整路径名字 newInstance() 创建类的实例 getPackage() 获得类的包 getSimpleName() 获得类的名字 getSuperclass() 获得当前类继承的父类的名字 getInterfaces() 获得当前类实现的类或是接口 获得类中注解相关的方法 方法 用途 getAnnotation(Class&lt; A &gt; annotationClass) 返回该类中与参数类型匹配的公有注解对象 getAnnotations() 返回该类所有的公有注解对象 getDeclaredAnnotation(Class&lt; A &gt; annotationClass) 返回该类中与参数类型匹配的所有注解对象 getDeclaredAnnotations() 返回该类所有的注解对象 获得类中属性相关的方法 方法 用途 getField(String name) 获得某个公有的属性对象 getFields() 获得所有公有的属性对象 getDeclaredField(String name) 获得某个属性对象 getDeclaredFields() 获得所有属性对象 获得类中构造器相关的方法 方法 用途 getConstructor(Class…&lt;?&gt; parameterTypes) 获得该类中与参数类型匹配的公有构造方法 getConstructors() 获得该类的所有公有构造方法 getDeclaredConstructor(Class…&lt;?&gt; parameterTypes) 获得该类中与参数类型匹配的构造方法 getDeclaredConstructors() 获得该类所有构造方法 获得类中方法相关的方法 方法 用途 getMethod(String name, Class…&lt;?&gt; parameterTypes) 获得该类某个公有的方法 getMethods() 获得该类所有公有的方法 getDeclaredMethod(String name, Class…&lt;?&gt; parameterTypes) 获得该类某个方法 getDeclaredMethods() 获得该类所有方法 类中其他重要的方法 方法 用途 isAnnotation() 如果是注解类型则返回true isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass) 如果是指定类型注解类型则返回true isAnonymousClass() 如果是匿名类则返回true isArray() 如果是一个数组类则返回true isEnum() 如果是枚举类则返回true isInstance(Object obj) 如果obj是该类的实例则返回true isInterface() 如果是接口类则返回true isLocalClass() 如果是局部类则返回true isMemberClass() 如果是内部类则返回true Field类Field代表类的成员变量（成员变量也称为类的属性）。 方法 用途 equals(Object obj) 属性与obj相等则返回true get(Object obj) 获得obj中对应的属性值 set(Object obj, Object value) 设置obj中对应属性值 Method类Method代表类的方法。 方法 用途 invoke(Object obj, Object… args) 传递object对象及参数，调用该对象对应的方法 带有Declared修饰的方法可以反射到私有的方法，没有Declared修饰的只能用来反射公有的方法 3.2、小Demo定义一个类，类名为 TestA ，类中有公有、私有属性，无参构造方法，公有、私有方法。 package reflact; public class TestA { public String name; private int age; public TestA() { System.out.println(&quot;构造方法执行了!&quot;); } public String PublicMethod() { System.out.println(&quot;PublicMethod 方法执行了!&quot;); System.out.println(&quot;name: &quot; + name + &quot;--- age: &quot; + age); return &quot;这是公共方法的返回值&quot;; } private String PrivateMethod() { System.out.println(&quot;PrivateMethod 方法执行了!&quot;); System.out.println(&quot;name: &quot; + name + &quot;--- age: &quot; + age); return &quot;这是私有方法的返回值&quot;; } } 利用反射机制设置、获取TestA类的属性，执行TestA类的方法。 package reflact; import java.lang.reflect.Field; import java.lang.reflect.Method; public class TestReflact { public static void main(String[] args) throws Exception { Class clazzA = Class.forName(&quot;reflact.TestA&quot;); System.out.println(&quot;类名为 ： &quot; + clazzA.getName()); // 构造 testA 实例 TestA testa = (TestA) clazzA.getDeclaredConstructor().newInstance(); // 设置、获取公有属性 Field name = clazzA.getField(&quot;name&quot;); name.set(testa, &quot;小明&quot;); System.out.println(name.get(testa)); // 对私有属性赋值、获取 Field age = clazzA.getDeclaredField(&quot;age&quot;); age.setAccessible(true); age.set(testa, 12); System.out.println(age.get(testa)); // 执行公共方法 Method PublicMethod = clazzA.getMethod(&quot;PublicMethod&quot;); Object invoke = PublicMethod.invoke(testa); System.out.println(invoke); // 执行私有方法 Method privateMethod = clazzA.getDeclaredMethod(&quot;PrivateMethod&quot;); privateMethod.setAccessible(true); Object invoke2 = privateMethod.invoke(testa); System.out.println(invoke2); } } 执行结果如图 参考文献Java高级特性——反射 Java 反射机制","categories":[],"tags":[],"keywords":[]},{"title":"hexo常用命令","slug":"hexo常用命令","date":"2019-10-26T02:57:22.000Z","updated":"2019-10-26T04:16:33.898Z","comments":true,"path":"2019/10/26/hexo常用命令/","link":"","permalink":"http://brucy.cn/2019/10/26/hexo常用命令/","excerpt":"","text":"Hexo常用命令一、安装、升级npm install hexo -g #安装 npm update hexo -g #升级 hexo init #初始化二、简写hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署三、服务器hexo server #Hexo 会监视文件变动并自动更新，您无须重启服务器。 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP hexo clean #清除缓存 网页正常情况下可以忽略此条命令 hexo g #生成静态网页 hexo d #开始部署四、监视文件变动hexo generate #使用 Hexo 生成静态文件快速而且简单 hexo generate --watch #监视文件变动五、完成后部署hexo generate --deploy hexo deploy --generate hexo deploy -g hexo server -g六、草稿hexo publish [layout] &lt;title&gt;七、模板hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&#39;ctrl + c&#39;关闭server） hexo deploy #将.deploy目录部署到GitHub hexo new [layout] &lt;title&gt; hexo new photo &quot;My Gallery&quot; hexo new &quot;Hello World&quot; --lang tw八、推送到服务器上hexo n #写文章 hexo g #生成 hexo d #部署 #可与hexo g合并为 hexo d -g参考于别人的简书","categories":[],"tags":[],"keywords":[]},{"title":"ArrayList","slug":"ArrayList","date":"2019-10-21T13:15:37.000Z","updated":"2020-02-11T14:00:01.339Z","comments":true,"path":"2019/10/21/ArrayList/","link":"","permalink":"http://brucy.cn/2019/10/21/ArrayList/","excerpt":"","text":"一、ArrayList 介绍1.1、概述 ArrayList 是一种变长集合，基于定长数组实现。 ArrayList 允许所有元素，包括null和重复元素。 ArrayList 类还提供了一些方法来操作数组的大小，每个ArrayList实例都有一个容量值。当往 ArrayList 中添加的元素数量大于其底层数组容量时，其会通过扩容机制对数组进行扩容。 ArrayList中size、isEmpty、get、set、iterator和listIterator操作在常数时间内运行。插入删除元素的时间复杂度为O（n）。所有其他操作基本都在线性时间内运行。 ArrayList 中的操作不是线程安全的！ 1.2、ArrayList 数据结构ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 // 由此构造方法可知 ArrayList 底层实现为数组 public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); } }1.3、继承关系 ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 ArrayList 实现了RandomAccess 接口， RandomAccess 是一个标志接口，表明实现这个接口的 List 集合是支持快速随机访问的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 ArrayList 实现了Cloneable 接口，即覆盖了函数 clone()，能被克隆。 ArrayList 实现java.io.Serializable 接口，这意味着ArrayList支持序列化，能通过序列化去传输。 二、ArrayList 源码详解2.1、ArrayList 中的属性 serialVersionUID 用于实例的序列化，为了保持版本的兼容性。 private static final long serialVersionUID = 8683452581122892189L; DEFAULT_CAPACITY 默认初始容量为 10 private static final int DEFAULT_CAPACITY = 10; EMPTY_ELEMENTDATA 用于空实例的共享空数组实例，当执行无参构造方法后，并未给 ArrayList 实例开辟存储空间，而是引用此空数组。 private static final Object[] EMPTY_ELEMENTDATA = {}; DEFAULTCAPACITY_EMPTY_ELEMENTDATA 用于默认大小的空实例的共享空数组实例，new 一个ArrayList 时会默认返回此数组，若ArrayList 被指定容量为 0 会返回EMPTY_ELEMENTDATA private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; elementData 存储ArrayList元素的数组缓冲区，该方法为非私有以此简化嵌套类访问 transient Object[] elementData; // 非私有以简化嵌套类访问 size 数组的大小（包含元素的个数） private int size;2.2、构造方法 构造具有指定初始容量的空列表。 如果初始容量为 0 ，将返回 EMPTY_ELEMENTDATA public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); } } 构造一个初始容量为10的空列表。在没有元素真正存入ArrayList时，并没有为ArrayList开辟10个存储空间 public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 public ArrayList(Collection&lt;? extends E&gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray 可能返回的不是Object类型的数组所以加上下面的语句用于判断 //这里用到了反射里面的getClass()方法 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // 若数组为空，用 EMPTY_ELEMENTDATA 替换 this.elementData = EMPTY_ELEMENTDATA; } } 2.3、常用API2.3.1、容量调整 modCount 表示从结构上修改此列表的次数。注意并不是改变容器内部存储的值，而是改变结构。在迭代器遍历元素时会校验迭代器中存储的modCount 是否与ArrayList 实例中的modCount相等，如果不相等就表示已经有其他线程修改了会抛出异常。 修改这个ArrayList实例的容量为列表的当前大小。使用此操作来最小化ArrayList实例的存储。 public void trimToSize() { modCount++; if (size &lt; elementData.length) { elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); } } 判断是否需要扩容。如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量public void ensureCapacity(int minCapacity) { if (minCapacity &gt; elementData.length &amp;&amp; !(elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA &amp;&amp; minCapacity &lt;= DEFAULT_CAPACITY)) { modCount++; grow(minCapacity); // grow 方法是真正用来扩容的方法 } } 要分配的数组的最大大小。试图分配更大的数组可能会导致OutOfMemoryError:请求的数组大小超过VM限制，.Integer.MAX_VALUE = 2147483647 解释一下为什么要减8：在这 8 Byte的存储中保存了数组的一些头信息。这样做还可以避免内存溢出！ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; grow是用来扩容的方法，确保它至少可以容纳由最小容量参数指定的元素数量 private Object[] grow(int minCapacity) { return elementData = Arrays.copyOf(elementData, newCapacity(minCapacity)); } private Object[] grow() { return grow(size + 1); } 改变容量值，返回给grow 方法。 private int newCapacity(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; // 扩容到原来容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 右移一位相当于除以2 if (newCapacity - minCapacity &lt;= 0) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) return Math.max(DEFAULT_CAPACITY, minCapacity); if (minCapacity &lt; 0) // 溢出 throw new OutOfMemoryError(); return minCapacity; } return (newCapacity - MAX_ARRAY_SIZE &lt;= 0) ? newCapacity : hugeCapacity(minCapacity); } 扩容到最大容量 private static int hugeCapacity(int minCapacity) { if (minCapacity &lt; 0) // 溢出 throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; }在这里可以看到ArrayList 的容量最大值任然可以扩容到 MAX_ARRAY_SIZE ，那么数组的头信息到底是怎么存储的呢？ 在别人的博客中找到了解释 1、存储 Headerwords(并不是在所有虚拟机中都这样，只是部分虚拟机在数组中保留了一些头信息)，因此该现象仅为部分存在； 2、避免内存溢出，减少出错几率； 3、最大值其实还是为Integer.MAX_VALUE，并不是Integer.MAX_VALUE-8。(因为只是为了规避不同平台机器内存溢出的风险) 2.3.2、常用API 返回List 中元素的数量 public int size() { return size; } - 判断List 是否为空public boolean isEmpty() { return size == 0; }- 判断List 中是否包含某个值public boolean contains(Object o) { return indexOf(o) &gt;= 0; }- 返回元素在List 中第一次出现的位置，如果List 中没有此元素则返回 -1public int indexOf(Object o) { return indexOfRange(o, 0, size); } int indexOfRange(Object o, int start, int end) { Object[] es = elementData; if (o == null) { for (int i = start; i &lt; end; i++) { if (es[i] == null) { return i; } } } else { for (int i = start; i &lt; end; i++) { if (o.equals(es[i])) { return i; } } } return -1; }- 返回元素在List 中最后一次出现的位置，如果List 中没有此元素则返回 -1 。lastIndexOfRange 与indexOfRange 方法相似，lastIndexOfRange 方法在倒着遍历。public int lastIndexOf(Object o) { return lastIndexOfRange(o, 0, size); } int lastIndexOfRange(Object o, int start, int end) { Object[] es = elementData; if (o == null) { for (int i = end - 1; i &gt;= start; i--) { if (es[i] == null) { return i; } } } else { for (int i = end - 1; i &gt;= start; i--) { if (o.equals(es[i])) { return i; } } } return -1; }- 克隆ArrayList 调用了Object 类中的 clone() 方法。public Object clone() { try { ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; } catch (CloneNotSupportedException e) { throw new InternalError(e); } }- 返回一个数组public Object[] toArray() { return Arrays.copyOf(elementData, size); } @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T[] toArray(T[] a) { if (a.length &lt; size) // Make a new array of a&#39;s runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; }- 位置访问操作@SuppressWarnings(&quot;unchecked&quot;) E elementData(int index) { return (E) elementData[index]; } @SuppressWarnings(&quot;unchecked&quot;) static &lt;E&gt; E elementAt(Object[] es, int index) { return (E) es[index]; }- 增删改查操作public E get(int index) { Objects.checkIndex(index, size); return elementData(index); } public E set(int index, E element) { Objects.checkIndex(index, size); E oldValue = elementData(index); elementData[index] = element; return oldValue; } private void add(E e, Object[] elementData, int s) { if (s == elementData.length) elementData = grow(); elementData[s] = e; size = s + 1; } public boolean add(E e) { modCount++; add(e, elementData, size); return true; } public void add(int index, E element) { rangeCheckForAdd(index); modCount++; final int s; Object[] elementData; if ((s = size) == (elementData = this.elementData).length) elementData = grow(); System.arraycopy(elementData, index, elementData, index + 1, s - index); elementData[index] = element; size = s + 1; } public E remove(int index) { Objects.checkIndex(index, size); final Object[] es = elementData; @SuppressWarnings(&quot;unchecked&quot;) E oldValue = (E) es[index]; fastRemove(es, index); return oldValue; } public boolean remove(Object o) { final Object[] es = elementData; final int size = this.size; int i = 0; found: { if (o == null) { for (; i &lt; size; i++) if (es[i] == null) break found; } else { for (; i &lt; size; i++) if (o.equals(es[i])) break found; } return false; } fastRemove(es, i); return true; } // 此方法是真正的进行删除的方法， private void fastRemove(Object[] es, int i) { modCount++; final int newSize; if ((newSize = size - 1) &gt; i) System.arraycopy(es, i + 1, es, i, newSize - i); es[size = newSize] = null; } public void clear() { modCount++; final Object[] es = elementData; for (int to = size, i = size = 0; i &lt; to; i++) es[i] = null; } public boolean addAll(Collection&lt;? extends E&gt; c) { Object[] a = c.toArray(); modCount++; int numNew = a.length; if (numNew == 0) return false; Object[] elementData; final int s; if (numNew &gt; (elementData = this.elementData).length - (s = size)) elementData = grow(s + numNew); System.arraycopy(a, 0, elementData, s, numNew); size = s + numNew; return true; } public boolean addAll(int index, Collection&lt;? extends E&gt; c) { rangeCheckForAdd(index); Object[] a = c.toArray(); modCount++; int numNew = a.length; if (numNew == 0) return false; Object[] elementData; final int s; if (numNew &gt; (elementData = this.elementData).length - (s = size)) elementData = grow(s + numNew); int numMoved = s - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size = s + numNew; return true; }- 比较相关方法public boolean equals(Object o) { if (o == this) { return true; } if (!(o instanceof List)) { return false; } final int expectedModCount = modCount; // ArrayList can be subclassed and given arbitrary behavior, but we can // still deal with the common case where o is ArrayList precisely boolean equal = (o.getClass() == ArrayList.class) ? equalsArrayList((ArrayList&lt;?&gt;) o) : equalsRange((List&lt;?&gt;) o, 0, size); checkForComodification(expectedModCount); return equal; } boolean equalsRange(List&lt;?&gt; other, int from, int to) { final Object[] es = elementData; if (to &gt; es.length) { throw new ConcurrentModificationException(); } var oit = other.iterator(); for (; from &lt; to; from++) { if (!oit.hasNext() || !Objects.equals(es[from], oit.next())) { return false; } } return !oit.hasNext(); } private boolean equalsArrayList(ArrayList&lt;?&gt; other) { final int otherModCount = other.modCount; final int s = size; boolean equal; if (equal = (s == other.size)) { final Object[] otherEs = other.elementData; final Object[] es = elementData; if (s &gt; es.length || s &gt; otherEs.length) { throw new ConcurrentModificationException(); } for (int i = 0; i &lt; s; i++) { if (!Objects.equals(es[i], otherEs[i])) { equal = false; break; } } } other.checkForComodification(otherModCount); return equal; } ### 2.3.4、四个内部类### private class Itr implements Iterator&lt;E&gt; private class ListItr extends Itr implements ListIterator&lt;E&gt; private class SubList extends AbstractList&lt;E&gt; implements RandomAccess static final class ArrayListSpliterator&lt;E&gt; implements Spliterator&lt;E&gt; ArrayList有四个内部类， 其中的Itr是实现了Iterator接口，同时重写了里面的hasNext()， next()， remove() 等方法； 其中的ListItr 继承 Itr，实现了ListIterator接口，同时重写了hasPrevious()， nextIndex()， previousIndex()， previous()， set(E e)， add(E e) 等方法，所以这也可以看出了 Iterator和ListIterator的区别: ListIterator在Iterator的基础上增加了添加对象，修改对象，逆向遍历等方法，这些是Iterator不能实现的。 ## 三、ArrayList 经典 demo ## package list;import java.util.ArrayList;import java.util.Iterator; public class ArrayListDemo { public static void main(String[] srgs){ ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); System.out.printf(&quot;Before add:arrayList.size() = %d\\n&quot;,arrayList.size()); arrayList.add(1); arrayList.add(3); arrayList.add(5); arrayList.add(7); arrayList.add(9); System.out.printf(&quot;After add:arrayList.size() = %d\\n&quot;,arrayList.size()); System.out.println(&quot;Printing elements of arrayList&quot;); // 三种遍历方式打印元素 // 第一种：通过迭代器遍历 System.out.print(&quot;通过迭代器遍历:&quot;); Iterator&lt;Integer&gt; it = arrayList.iterator(); while(it.hasNext()){ System.out.print(it.next() + &quot; &quot;); } System.out.println(); // 第二种：通过索引值遍历 System.out.print(&quot;通过索引值遍历:&quot;); for(int i = 0; i &lt; arrayList.size(); i++){ System.out.print(arrayList.get(i) + &quot; &quot;); } System.out.println(); // 第三种：for循环遍历 System.out.print(&quot;for循环遍历:&quot;); for(Integer number : arrayList){ System.out.print(number + &quot; &quot;); } // toArray用法 // 第一种方式(最常用) Integer[] integer = arrayList.toArray(new Integer[0]); // 第二种方式(容易理解) Integer[] integer1 = new Integer[arrayList.size()]; arrayList.toArray(integer1); // 抛出异常，java不支持向下转型 //Integer[] integer2 = new Integer[arrayList.size()]; //integer2 = arrayList.toArray(); System.out.println(); // 在指定位置添加元素 arrayList.add(2,2); // 删除指定位置上的元素 arrayList.remove(2); // 删除指定元素 arrayList.remove((Object)3); // 判断arrayList是否包含5 System.out.println(&quot;ArrayList contains 5 is: &quot; + arrayList.contains(5)); // 清空ArrayList arrayList.clear(); // 判断ArrayList是否为空 System.out.println(&quot;ArrayList is empty: &quot; + arrayList.isEmpty()); }}","categories":[{"name":"Java API","slug":"Java-API","permalink":"http://brucy.cn/categories/Java-API/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"http://brucy.cn/tags/ArrayList/"}],"keywords":[{"name":"Java API","slug":"Java-API","permalink":"http://brucy.cn/categories/Java-API/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-10-19T05:20:27.266Z","updated":"2019-10-19T05:20:27.266Z","comments":true,"path":"2019/10/19/hello-world/","link":"","permalink":"http://brucy.cn/2019/10/19/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[],"keywords":[]}]}